{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.008s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1ea2a5c0f08>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unittest\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from functions import fillna_by_time, Check_fillna_by_time\n",
    "unittest.main(argv=[\"\", \"Check_fillna_by_time\"], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info = pd.read_csv('.\\data\\\\building_metadata.csv')\n",
    "train_meters = pd.read_csv('.\\data\\\\train.csv')\n",
    "weather_train = pd.read_csv('.\\data\\\\weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
       "0        0            0   Education         7432      2008.0          NaN\n",
       "1        0            1   Education         2720      2004.0          NaN\n",
       "2        0            2   Education         5376      1991.0          NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate tasks\n",
    "electricity = train_meters[train_meters.meter==0].drop('meter', axis=1)[:100000] # careful!!!\n",
    "chilledwater = train_meters[train_meters.meter==1].drop('meter', axis=1)\n",
    "steam = train_meters[train_meters.meter==2].drop('meter', axis=1)\n",
    "hotwater = train_meters[train_meters.meter==3].drop('meter', axis=1)\n",
    "\n",
    "del train_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with electricity\n",
    "# we should join dataframes to see the whole picture\n",
    "electricity = electricity.set_index('building_id').join(\n",
    "    building_info.set_index('building_id'), \n",
    "    on='building_id')\n",
    "electricity.set_index(pd.Index([i for i in range(len(electricity))]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove nans\n",
    "electricity['floor_count'].fillna(electricity['floor_count'].median(), inplace=True)\n",
    "electricity['year_built'].fillna(electricity['year_built'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column timestamp doesn't have Nans\n",
      "column meter_reading doesn't have Nans\n",
      "column site_id doesn't have Nans\n",
      "column primary_use doesn't have Nans\n",
      "column square_feet doesn't have Nans\n",
      "column year_built doesn't have Nans\n",
      "column floor_count doesn't have Nans\n"
     ]
    }
   ],
   "source": [
    "for i in electricity.columns:\n",
    "    part = 'has Nans!!!' if electricity[i].isna().any() else 'doesn\\'t have Nans'\n",
    "    print(f'column {i} {part}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 unique site_ids\n",
      "But for every site_id there are in average 8735 rows\n",
      "We are going to have 873500000 raws at all!!!\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(weather_train['site_id'].unique()), 'unique site_ids')\n",
    "\n",
    "mean_for_site_id = 0\n",
    "for i in weather_train['site_id'].unique():\n",
    "    mean_for_site_id += weather_train['site_id'][weather_train['site_id'] == i].count()\n",
    "mean_for_site_id /= len(weather_train['site_id'].unique())\n",
    "\n",
    "print('But for every site_id there are in average', int(mean_for_site_id), 'rows')\n",
    "print('We are going to have', int(mean_for_site_id)*len(electricity),'raws at all!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 0 0.5429189435336976 of data doesn't have Nans at all\n",
      "for 1 0.0 of data doesn't have Nans at all\n",
      "for 2 0.6747125128088353 of data doesn't have Nans at all\n",
      "for 3 0.5714123006833713 of data doesn't have Nans at all\n",
      "for 4 0.4361835363770921 of data doesn't have Nans at all\n",
      "for 5 0.0 of data doesn't have Nans at all\n",
      "for 6 0.5867683898884081 of data doesn't have Nans at all\n",
      "for 7 0.0 of data doesn't have Nans at all\n",
      "for 8 0.5429189435336976 of data doesn't have Nans at all\n",
      "for 9 0.44123006833712985 of data doesn't have Nans at all\n",
      "for 10 0.666021407424277 of data doesn't have Nans at all\n",
      "for 11 0.0 of data doesn't have Nans at all\n",
      "for 12 0.0 of data doesn't have Nans at all\n",
      "for 13 0.49379483092337473 of data doesn't have Nans at all\n",
      "for 14 0.5924575595305913 of data doesn't have Nans at all\n",
      "for 15 0.006505796072864916 of data doesn't have Nans at all\n"
     ]
    }
   ],
   "source": [
    "for index in weather_train['site_id'].unique():\n",
    "    testing_site_id = weather_train[weather_train['site_id'] == index]\n",
    "    \n",
    "    with_nans = testing_site_id['air_temperature'].isna()\n",
    "    for i in testing_site_id.columns:\n",
    "        with_nans |= testing_site_id[i].isna()\n",
    "\n",
    "    print('for', index, len(testing_site_id[~with_nans])/len(testing_site_id), \n",
    "          'of data doesn\\'t have Nans at all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  \\\n",
       "0             25.0             6.0             20.0               -1.0   \n",
       "1             24.4             6.0             21.1               -1.0   \n",
       "2             22.8             2.0             21.1                0.0   \n",
       "\n",
       "   sea_level_pressure  wind_direction  wind_speed  \n",
       "0              1019.7             0.0         0.0  \n",
       "1              1020.2            70.0         1.5  \n",
       "2              1020.2             0.0         0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# research features for each site_id == 0\n",
    "# drop time and site_id because they are not useful now\n",
    "# (time just shows us the order to sort)\n",
    "testing_site_id = weather_train[weather_train['site_id'] == 0].drop('site_id', axis=1)\n",
    "for i in testing_site_id.columns[1:]:\n",
    "    testing_site_id = fillna_by_time(testing_site_id, i)\n",
    "testing_site_id = testing_site_id.drop('timestamp', axis=1)\n",
    "\n",
    "testing_site_id.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAK7CAYAAADm9tljAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde7xcVX338c+XhFsQSEICQhI8ASIVeBTpEfAeuQakxvYBBRQDxqa24L3KRZ+SqrRYrQjFYoOJQEVCpKipRSFyLVUuCQICwRJDSA4EEkgCKAoGfs8faw3sTGbmzLnOPnO+79drXmfvtdfee+05s2b/9pq111ZEYGZmZmZmtW3R6gKYmZmZmZWZA2YzMzMzswYcMJuZmZmZNeCA2czMzMysAQfMZmZmZmYNOGA2MzMzM2vAAXMJSPqApOtaXQ4za46kkyXdOkDbXiHpsIHYtlm7knSJpC+3uhzWvhwwl0BEXB4RR/RmXUkhaa/+LlMr+AvPzMzKzOfc4csBc8lJGtnqMvSHwTiOdnmvzMrOdc2s3HzO7X8OmAeRpDMk/UbSs5IekPTnOX2Tn3fzFeypkh4CHmqwvVvy5D2Sfivp/Tn9GEl3S9og6eeSXl9YZ4Wkz0q6V9LvJM2VtIukn+Ry/UzSmJy3I5dllqTHJK2W9JnCtrYoHNNTkhZIGlu17kxJK4Ebcvr3JT0u6WlJt0jaN6fPAj4AfC4fy38W3ou9Cvt8+YpY0lRJXZJOl/Q48J3ujt+spyRNknS1pLX5c35hjTxvkXRn/lzfKekthWWbdLGQNFvSdwvzJ0l6JG/7802WaYSkswrfJ0skTWpUFknHS1pctZ1PSVqYp7eW9DVJKyU9IelbkrbNyzara5LGSPpxfl/W5+mJhW1PznW88r3yzarjPjjXzw2S7pE0tZljNwOQ9EZJd+XP15XANoVlNc8Bkk6pnFvy/DJJCwrzqyTt32CfPucO53NuRPg1SC/gOGA30oXK+4HfAbsCJwO3FvIFsAgYC2zbzTYD2KswfwCwBjgIGAHMAFYAW+flK4DbgF2ACTnvXcAbga1JlezsnLcjb/8KYDvg/wBrgcPy8k/mbU3M6/4bcEXVupfldbfN6R8Gts/5vwHcXSj7JcCXuzm+l/MAU4GNwFfy9rbt7vj98qsnr/wZugc4L3+OtwHeVqyzuZ6uB04CRgIn5Pmd8vIVlTqT52cD383T+wC/Bd6RP8Nfz5/pw7op12eBXwF7AwLeAOzUqCzAKOBZYEphO3cCx+fpbwAL8za2B/4T+Me8rFZd2wn4v3m72wPfB35Y2PYvgK8BW+X37JnCcU8AngKOJn0fHp7nx7f6f+5X+V/5M/UI8ClgS+BY4I/AlxudA4A9gA35M7dr3sajeZt75LqyRTf79jl3mJ5zW16A4fwC7gamUztgPqTJbVR/uC8CvlSV59fAO/P0CuADhWX/AVxUmP8Y+aRXqIB/Ulj+T8DcPL0UOLSwbFfSl9bIwrp7NCj76Jxnxzzfm8r7ArBNs8fvl189eQFvzieskVXpL9dZUnB6R9XyXwAn5+kV1A+Y/w6YX1i2Xf5Mdxcw/xqYXiO9u7J8F/i7PD2FFECPIgXdvwP2rDr2h/P0ZnWtxr73B9bn6d1JJ9ZRheXfLRz36cC/V61/LTCj1f9zv8r/Il1gPgaokPZzUsDc3TlwFSnIOx6YA9wB/AlwCrCwiX37nDtMz7nukjGIJH2o8LPFBmA/YFyd7Kt6uZvXAJ+p7CPvZxKpZbviicL072vMv6pBWR4pbOs1wA8K+1kKvEi6kt5s3fwz8rn556RnSF8kUP89aMbaiPhDYb6Z4zdr1iTgkYjY2CDPbqR6UfQIqTWpO7tRqCMR8TtSS2sz5fpNL8ryPVKrM8CJpBP1c8B4UuC8pFBvfprTKzapa5JGSfo3pe4kzwC3AKMljcjlWJe3XVH8HnkNcFxVPX0bKQAw685upJbhKKRVPvfdnQNuJgV+78jTNwHvzK+be1EWn3OHyTnXAfMgkfQa4GLgNNJPtaOB+0gtO7VEnfTurALOiYjRhdeoiLiil9uD9OGv2J10ZV/Z11FV+9omIh4t5C8ex4mkFvXDgB1JV8TwyntQ65ifI53IK15dtbx6nYE4fhu+VgG7q/HNLY+RThpFuwOVevA76n+GV1OoX5JGkbo6NFOuPXtRluuAcbmf5gmkABrgSdKJe99CvdkxIoon8uq69hlSl5CDImIHUgACqT6vBsbm46kofo+sIrUwF+vpdhFxbjfHbQbp8zVBUvH8uXv+2905oBIwvz1P30zfAmafc4fJOdcB8+DZjvRBWwvp5gNSC3NfPUHqe1VxMfBRSQcp2U7SuyVt34d9/L/cmrQv6WerK3P6t4Bz8sUAksZLmt5gO9sDz5Na0EYB/9DNsUDqtnJivlKeRvpSa2Qgjt+GrztIJ+dz82dpG0lvrcpzDfBaSSdKGql0I9A+wI/z8ruB4yVtKamT1N+y4irgGElvk7QV8EWa+17+NvAlSVPy5/z1knbqriy5pfwq4KukvsqLcvpLpLpznqSdASRNkHRkgzJsTwqyN+Qbj86uLIiIR4DFwGxJW0l6M/BnhXW/C/yZpCNz3d4m31A0EbPu/YLU5efj+XP+F8CBeVl354CbgXeR+vh2Af8NTCNdqP6yiX37nLupYXPOdcA8SCLiAeCfSRX9CVJn/v/ph03PBi7NP4W8LyIWA38JXEi6gWEZqb9lX9yct3M98LWIqDxk5XzSTULXSXqWdDPCQQ22cxn5JgvggZy/aC6wTz6WH+a0T5BOtBtId/T+kAYG6PhtmIqIF0mfv72AlUAX6YbdYp6ngGNILa5PAZ8DjomIJ3OW/0dqDV4P/D2vtOoSEfcDp+a01TlPVxNF+zqwgNRi/Ayp7mzbRFnI+zoM+H5VV5PTSfXltvzz7c9ILcj1fIN008+TpLr806rlHyD1g36K1Lf0StLJm4hYRWr5OovUiLCKdCOjz0nWrYh4AfgL0nf7elKdvDova3gOiIj/Jd1o+995/hlgOfA/ub53ZzY+575sOJ1ztWkXILNXSOoAHga27KYPp5lZQ0pDfz0YEWd3m9lsGPI5t9x8NW9mZv1O0psk7ak0duw0Uotyw9YqM7OycsBccpLerjSo+GavVpfNzAaO0oMNatX9s1pdtia9mjQCwW+BC4C/johm+oiatYzPuVaPu2SYmZmZmTXgFmYzMzMzswYajS1aCuPGjYuOjo5WF8OsNJYsWfJkRIzvPufgc30125Trq9nQ0ai+lj5g7ujoYPHixa0uhllpSKp+kltpuL6abcr11WzoaFRf3SXDzMzMzKwBB8xmZmZmZg04YDYzMzMza8ABs5mZmZlZAw6YzczMzMwacMBsZmZmZtaAA2YzMzMzswYcMJu1EUmTJN0oaamk+yV9IqfPlvSopLvz6+jCOmdKWibp15KOLKRPy2nLJJ3RiuMxMzMrg9I/uMSGn9mz+yfPMLUR+ExE3CVpe2CJpEV52XkR8bViZkn7AMcD+wK7AT+T9Nq8+JvA4UAXcKekhRHxwKAcxTDlz76Z2abK8r3ogNmsjUTEamB1nn5W0lJgQoNVpgPzI+J54GFJy4AD87JlEbEcQNL8nNcBs5mZDTvukmHWpiR1AG8Ebs9Jp0m6V9I8SWNy2gRgVWG1rpxWL73WfmZJWixp8dq1a/vxCMzMzMrBAbNZG5L0KuA/gE9GxDPARcCewP6kFuh/rmStsXo0SN88MWJORHRGROf48eP7XHYzM7OycZcMszYjaUtSsHx5RFwNEBFPFJZfDPw4z3YBkwqrTwQey9P10s3MzIYVtzCbtRFJAuYCSyPi64X0XQvZ/hy4L08vBI6XtLWkycAU4A7gTmCKpMmStiLdGLhwMI7BbDjJXaTWSLqvKv1jeZSa+yX9UyHdo9qYtYBbmM3ay1uBk4BfSbo7p50FnCBpf1K3ihXAXwFExP2SFpBu5tsInBoRLwJIOg24FhgBzIuI+wfzQMyGiUuAC4HLKgmS3kW6yfb1EfG8pJ1zuke1MWsRB8xmbSQibqV2/+NrGqxzDnBOjfRrGq1nZn0XEbfkG3SL/ho4N49eQ0Ssyeke1casRdwlw8zMrFxeC7xd0u2Sbpb0ppzuUW3MWsQBs5mZWbmMBMYABwOfBRbk+xM8qo1Zi7hLhpmZWbl0AVdHRAB3SHoJGIdHtTFrGbcwm5mZlcsPgUMA8k19WwFP4lFtzFrGLcxmZmYtIukKYCowTlIXcDYwD5iXh5p7AZiRW5s9qo1ZizhgNjMza5GIOKHOog/Wye9RbcxaoNsuGbUGVZf0VUkPSrpX0g8kjS4s86DqZmZmZtY2munDfAkwrSptEbBfRLwe+F/gTNhsUPVpwL9KGiFpBGlQ9aOAfUgPUdinX47AzMzMzGwAdRswR8QtwLqqtOsiYmOevY10Ry4UBlWPiIeByqDqB5IHVY+IF4DKoOpmZmZmZqXWH6NkfBj4SZ7u86Dq4IHVzczMzKw8+hQwS/o86U7dyytJNbL1aFB18MDqZmZmZlYevR4lQ9IM4Bjg0DzcDXhQdTOzYWX27P7JY2ZWZr1qYZY0DTgdeE9EPFdY5EHVzczMzKytdNvCXGdQ9TOBrYFF6fH23BYRH40ID6puZmZmZm2l24C5zqDqcxvk96DqZmZmZtY2+mOUDDMzMzOztuWA2czMzMysAQfMZmZmZmYNOGA2MzMzM2vAAbOZmVmLSJonaY2k+2os+1tJIWlcnpekCyQtk3SvpAMKeWdIeii/ZgzmMZgNBw6YzczMWucSYFp1oqRJwOHAykLyUaTnG0wBZgEX5bxjSUO+HgQcCJwtacyAltpsmHHAbGZm1iIRcQuwrsai84DPAVFImw5cFsltwGhJuwJHAosiYl1ErAcWUSMIN7Pec8BsZmZWIpLeAzwaEfdULZoArCrMd+W0eum1tj1L0mJJi9euXduPpTZrbw6YzczMSkLSKODzwN/VWlwjLRqkb54YMSciOiOic/z48b0vqNkw44DZzMysPPYEJgP3SFoBTATukvRqUsvxpELeicBjDdLNrJ84YDYzMyuJiPhVROwcER0R0UEKhg+IiMeBhcCH8mgZBwNPR8Rq4FrgCElj8s1+R+Q0M+snDpjNzMxaRNIVwC+AvSV1SZrZIPs1wHJgGXAx8DcAEbEO+BJwZ359MaeZWT8Z2eoCmFn/ysNRXQa8GngJmBMR5+ehp64EOoAVwPsiYr0kAecDRwPPASdHxF15WzOAL+RNfzkiLh3MYzFrdxFxQjfLOwrTAZxaJ988YF6/Fs7MXuYWZrP2sxH4TES8DjgYOFXSPsAZwPURMQW4Ps+Dx3Y1MzNryAGzWZuJiNWVFuKIeBZYShpiajpQaSG+FHhvnvbYrmZmZg04YDZrY5I6gDcCtwO75BuEyH93ztn6NLarx3U1M7N254DZrE1JehXwH8AnI+KZRllrpDU9tqvHdTUzs3bngNmsDUnakhQsXx4RV+fkJ3JXC/LfNTndY7uamZk10FTALGmepDWS7iukjZW0SNJD+e+YnC5JF0haJuleSQcU1pmR8z+U7743s36WR72YCyyNiK8XFi0EKvVuBvCjQrrHdjUzM6uj2RbmS9j8Zh/fcW9WTm8FTgIOkXR3fh0NnAscLukh4PA8Dx7b1czMrKGmxmGOiFvyzUNF04GpefpS4CbgdAp33AO3SarccT+VfMc9gKTKHfdX9OkIzGwTEXErtfsfAxxaI7/HdjUzM2ugL32YB+SOezMzMzOzMhmIm/76dMc9eJgqMzMzMyuPvjwa+wlJu0bE6h7ccT+1Kv2mWhuOiDnAHIDOzs6aQbUNb7Nn908eMzMzs+70pYXZd9ybmZmZWdtrdli5K4BfAHtL6pI0E99xb2Zm1id1hm39qqQH89CsP5A0urDszDxs668lHVlIn5bTlkk6o3o/ZtY3zY6ScUKdRb7j3nrE3STMzDZxCXAhcFkhbRFwZkRslPQV4EzgdEn7AMcD+wK7AT+T9Nq8zjdJjVddwJ2SFkbEA4N0DGZtz0/6MzMza5GIuAVYV5V2XURszLO3ke75gTRs6/yIeD4iHib9kntgfi2LiOUR8QIwP+c1s37igNnMzKy8Pgz8JE972FazFnHAbGZmVkKSPg9sBC6vJNXI5mFbzQZBX4aVMzMb8jxEoZWRpBnAMcCh+d4gqD9sKw3SN+FhW816xy3MZmZmJSJpGnA68J6IeK6waCFwvKStJU0GpgB3kEaemiJpsqStSDcGLhzscpu1M7cwm5mZtUgetnUqME5SF3A2aVSMrYFFkgBui4iPRsT9khYAD5C6apwaES/m7ZxGerbBCGBeRNw/6Adj1sYcMJuZmbVInWFb5zbIfw5wTo30a0jPQTCzAeAuGWZmZmZmDThgNjMzMzNrwAGzmZmZmVkD7sNsTfHQW2ZmZjZcuYXZzMzMzKwBB8xmZmZmZg04YDYzMzMza8ABs5mZmZlZAw6YzczMzMwacMBsZmZmZtaAA2YzMzMzswYcMJuZmZmZNdCngFnSpyTdL+k+SVdI2kbSZEm3S3pI0pWStsp5t87zy/Lyjv44ADMzMzOzgdTrgFnSBODjQGdE7AeMAI4HvgKcFxFTgPXAzLzKTGB9ROwFnJfzmZmZDVuS5klaI+m+QtpYSYtyw9MiSWNyuiRdkBue7pV0QGGdGTn/Q5JmtOJYzNpZXx+NPRLYVtIfgVHAauAQ4MS8/FJgNnARMD1PA1wFXChJERF9LIOZFUiaBxwDrMkXs0iaDfwlsDZnOysirsnLziRd0L4IfDwirs3p04DzSRfD346IcwfzOMyGiUuAC4HLCmlnANdHxLmSzsjzpwNHAVPy6yDSufUgSWOBs4FOIIAlkhZGxPpBOwqzXpg9u9UlaF6vW5gj4lHga8BKUqD8NLAE2BARG3O2LmBCnp4ArMrrbsz5d6q1bUmzJC2WtHjt2rW1sphZfZcA02qknxcR++dXJVjeh/TL0L55nX+VNELSCOCbpBP0PsAJOa+Z9aOIuAVYV5U8ndTgRP773kL6ZZHcBoyWtCtwJLAoItblIHkRtb8DzKyX+tIlYwyp8k4GdgO2I51cq1VakNVg2aaJEXMiojMiOsePH9/bIpoNS3VOwPVMB+ZHxPMR8TCwDDgwv5ZFxPKIeAGYn/Oa2cDbJSJWA+S/O+f0lxueskqjVL30zbhByqx3+nLT32HAwxGxNiL+CFwNvIV0xVvp6jEReCxPdwGTAPLyHWn+pG5mfXda7vc4r9InEp+AzYaSeg1PbpAyG2B9CZhXAgdLGiVJwKHAA8CNwLE5zwzgR3l6YZ4nL7/B/ZfNBs1FwJ7A/qQuVP+c030CNiufJ3JXC/LfNTn95YanrNIoVS/dzPpJX/ow3066ee8u4Fd5W3NINyZ8WtIyUh/luXmVucBOOf3TpJsYzGwQRMQTEfFiRLwEXEzqcgE+AZuVUbGBqbrh6UN5tIyDgadzl41rgSMkjcm/Hh2R08ysn/RplIyIOJt0Z27Rcl45GRfz/gE4ri/7M7PekbRrpU8k8OdAZQirhcD3JH2ddC/CFOAOUgvzFEmTgUdJNwaeiJn1K0lXAFOBcZK6SOfUc4EFkmaSfs2tnDuvAY4m3WvwHHAKQESsk/Ql4M6c74sR4S6PZv2or8PKmVnJ1DkBT5W0P6lbxQrgrwAi4n5JC0jdqTYCp0bEi3k7p5FaqUYA8yLi/kE+FLO2FxEn1Fl0aI28AZxaZzvzgHn9WDSzupoZDm4oDRnXDAfMZm2mzgl4bo20Sv5zgHNqpF9DatEyMzMb1vr0aGwzMzMzs3bngNnMzMzMrAEHzGZmZmZmDThgNjMzMzNrwAGzmZmZmVkDHiXD+k27DSFjZmZmBm5hNjMzMzNryAGzmZmZmVkDDpjNzMzMzBpwH2ZrW8Px0Z1mZmbW/9zCbGZmZmbWgANmMzMzM7MG3CXDzMyshCR9CvgIEMCvgFOAXYH5wFjgLuCkiHhB0tbAZcCfAk8B74+IFa0otxm0X5dHB8xmZtY22uXeBUkTgI8D+0TE7yUtAI4HjgbOi4j5kr4FzAQuyn/XR8Reko4HvgK8v0XFN2s77pJhZmZWTiOBbSWNBEYBq4FDgKvy8kuB9+bp6XmevPxQSRrEspq1NQfMZmZmJRMRjwJfA1aSAuWngSXAhojYmLN1ARPy9ARgVV53Y86/U/V2Jc2StFjS4rVr1w7sQZi1kT4FzJJGS7pK0oOSlkp6s6SxkhZJeij/HZPzStIFkpZJulfSAf1zCGZmZu0lnzunA5OB3YDtgKNqZI3KKg2WvZIQMSciOiOic/z48f1VXLO219c+zOcDP42IYyVtRfrJ6Czg+og4V9IZwBnA6aSKPiW/DiL1uTqoj/s3MzNrR4cBD0fEWgBJVwNvAUZLGplbkScCj+X8XcAkoCt34dgRWDf4xbZ2MBT6+Q+2XrcwS9oBeAcwFyAiXoiIDWzaj6q6f9VlkdxGqvS79rrkZmZm7WslcLCkUbkv8qHAA8CNwLE5zwzgR3l6YZ4nL78hIjZrYTaz3ulLl4w9gLXAdyT9UtK3JW0H7BIRqwHy351z/pf7V2XFvldmZmaWRcTtpJv37iINKbcFMIf0i+2nJS0j9VGem1eZC+yU0z9N+nXXzPpJX7pkjAQOAD4WEbdLOp/GFbSp/lWQbkoAZgHsvvvufSiimZnZ0BQRZwNnVyUvBw6skfcPwHGDUS6z4agvLcxdQFe+CoZ0JXwA8ESlq0X+u6aQf1Jh/WLfq034pgQzMzMzK4teB8wR8TiwStLeOanSv6rYj6q6f9WH8mgZBwNPV7pumJmZmZmVVV9HyfgYcHkeIWM56bGdWwALJM0k3bRQ+YnoGtITipYBz+W8ZmZmZmal1qeAOSLuBjprLDq0Rt4ATu3L/szMzMzMBltfW5itDXi8RTMzM7P6/GhsMzMzM7MG3MJs1mYkzQOOAdZExH45bSxwJdABrADeFxHr8wMRzifdX/AccHJE3JXXmQF8IW/2yxFxKWZmVlrN/GLsX5V7xwGzWfu5BLgQuKyQdgY9eGR9DrDPJt2jEMASSQsjYv2gHYWZmVkTBuNCwV0yzNpMRNwCrKtK7ukj648EFkXEuhwkLwKmDXzpzczMyscBs9nw0NNH1jf9KHtJsyQtlrR47dq1/V5wMzOzVnOXDBvW3N+r7iPrm36UfUTMAeYAdHZ21sxjZmY2lLmF2Wx46Okj65t+lL2ZmVm7c8BsNjz09JH11wJHSBojaQxwRE4zMzMbdhwwm7UZSVcAvwD2ltSVH1N/LnC4pIeAw/M8pEfWLyc9sv5i4G8AImId8CXgzvz6Yk4zs0EiabSkqyQ9KGmppDdLGitpkaSH8t8xOa8kXSBpmaR7JR3Q6vKbtRP3YTZrMxFxQp1FPXpkfUTMA+b1Y9HMrGfOB34aEcdK2goYBZxFD4aIbE2xzdqPA2YzG1S+0dKse5J2AN4BnAwQES8AL0iaDkzN2S4FbiIFzC8PEQncllund62MjmNmfeMuGWZmZuWzB7AW+I6kX0r6tqTt6PkQkZvwMJBmveOA2czMrHxGAgcAF0XEG4Hfkbpf1NPUUJARMSciOiOic/z48f1TUrNhwAGzmZlZ+XQBXRFxe56/ihRA93SISDPrBw6YzczMSiYiHgdWSdo7Jx0KPEDPh4g0s37gm/7MzMzK6WPA5XmEjOXAKaSGrgV5uMiVwHE57zXA0aQhIp/Lec2snzhgNjMzK6GIuBvorLGoR0NEmlnfuUuGmZmZmVkDfQ6YJY3IQ978OM9PlnR7fgrRlfmnJCRtneeX5eUdfd23mZmZmdlA648W5k8ASwvzXwHOi4gpwHpgZk6fCayPiL2A83I+MzMzM7NS61MfZkkTgXcD5wCfliTgEODEnOVSYDbpEZ3T8zSk4XEulKTc78rMzMzMBpifpNo7fW1h/gbwOeClPL8TsCEiNub54pOGXn4KUV7+dM6/GT+JyMzMzMzKotctzJKOAdZExBJJUyvJNbJGE8s2TYyYA8wB6OzsdAt0H/hK0szMzKxv+tIl463AeyQdDWwD7EBqcR4taWRuRS4+aajyFKIuSSOBHYF1fdi/2aBo5qLDFyZmZmbtq9ddMiLizIiYGBEdwPHADRHxAeBG4NicrfopRJWnEx2b87v12MzMzMxKbSDGYT6ddAPgMlIf5bk5fS6wU07/NHDGAOzbzMzMzKxf9cuT/iLiJuCmPL0cOLBGnj/wyiM8zczMzMyGBD/pz8zMzMysAQfMZmZmZmYN9EuXDGsNj8xgZtbeJI0AFgOPRsQxkiYD84GxwF3ASRHxgqStgcuAPwWeAt4fEStaVGyztuMWZjMzs/L6BLC0MP8V4LyImAKsB2bm9JnA+ojYCzgv5zOzfuKA2czMrIQkTQTeDXw7zws4BLgqZ7kUeG+enp7nycsPzfnNrB84YDYzMyunbwCfA17K8zsBG/KDwSA9EGxCnp4ArALIy5/O+c2sH7gPs5mZWclIOgZYExFLJE2tJNfIGk0sK253FjALYPfdd++Hktpg8X1LreUWZjMzs/J5K/AeSStIN/kdQmpxHi2p0tg1EXgsT3cBkwDy8h2BddUbjYg5EdEZEZ3jx48f2CMwayMOmM3MzEomIs6MiIkR0QEcD9wQER8AbgSOzdlmAD/K0wvzPHn5DRGxWQuzmfWOA2YzM7Oh43Tg05KWkfooz83pc4GdcvqngTNaVD6ztuQ+zGbDSP5591ngRWBjRHRKGgtcCXQAK4D3RcT6fIf9+cDRwHPAyRFxVyvKbTacRcRNwE15ejlwYI08fwCOG9SCmQ0jbmE2G37eFRH7R0Rnnj8DuD6P63o9r7RMHQVMya9ZwEWDXlIzM7MScMBsZsXxW6vHdb0skttINxvt2ooCmpmZtZIDZrPhJYDrJC3Jw0sB7BIRqwHy351z+svjumbFMV9fJmmWpMWSFq9du3YAi25mZtYa7sNsNry8NSIek7QzsEjSgw3yNjWua0TMAeYAdHZ2+q58MzNrO25hNhtGIuKx/HcN8APSzUNPVLpa5L9rcvaXx3XNimO+mpmZDRtuYS4pP9HH+puk7YAtIuLZPH0E8EVeGb/1XDYf168kYTwAACAASURBVPU0SfOBg4CnK103zMzMhhMHzGbDxy7AD9JocYwEvhcRP5V0J7BA0kxgJa8MTXUNaUi5ZaRh5U4Z/CKbmZm1Xq8DZkmTgMuAVwMvAXMi4nyP6WpWTnn81jfUSH8KOLRGegCnDkLRzMyGNf+qXH59aWHeCHwmIu6StD2wRNIi4GTSmK7nSjqDNKbr6Ww6putBpDFdD+pL4c3KopkvO38hmpmZDU29vukvIlZXWogj4llgKWnIKY/pamZmZmZto19GyZDUAbwRuJ0+julqZmZmZlYmfQ6YJb0K+A/gkxHxTKOsNdJqjtnqByGYmZmZWVn0KWCWtCUpWL48Iq7OyX0e0zUi5kREZ0R0jh8/vi9FNDMzMzPrk14HzHnUi7nA0oj4emFRZUxX2HxM1w8pORiP6WpmZlaTpEmSbpS0VNL9kj6R08dKWiTpofx3TE6XpAskLZN0r6QDWnsEZu2lLy3MbwVOAg6RdHd+HU16+MHhkh4CDs/zkMZ0XU4a0/Vi4G/6sG8zM7N2VhmJ6nXAwcCpkvYhjTx1fURMAa7P87DpSFSzSCNRmVk/6fWwchFxK7X7JYPHdG3Iw4uZmVkj+RfYyg30z0oqjkQ1NWe7FLiJNHTryyNRAbdJGi1pV/+Sa9Y/+mWUDDMzMxsYHonKrPX8aGwzM7OSqh6JKj/avmbWGmmbjUQlaRapywa77757fxXTGvCvyu3BLcxmZmYlNBAjUXkUKrPeccBsZmZWMh6Jyqxc3CXDzMysfCojUf1K0t057SzSyFMLJM0EVgLH5WXXAEeTRqJ6DjhlcIs7PLm7xfDhgLmfufKYmVlfeSSqgdXMudrncytylwwzMzMzswYcMJuZmZmZNeAuGWZmZmZV3CXDihww94Arj5mZmdnw44DZzMzM2oYbt2wguA+zmZmZmVkDbmE2GyQexsjMzGxocguzmZmZmVkDbmE2MzOzIcG/wlmrOGDOXAnNzMzMrBYHzGZmZtZybriyMnMfZjMzMzOzBoZFC7OvWs3MzMystwa9hVnSNEm/lrRM0hmDvX8za57rq9nQ4jprNjAGtYVZ0gjgm8DhQBdwp6SFEfFAX7brFmSz/jdQ9dVsKBiK46aXuc6W7b0y66nB7pJxILAsIpYDSJoPTAdaXpnNbDOur2ZDS0vqrINhGw4UEYO3M+lYYFpEfCTPnwQcFBGnVeWbBczKs/sB9w1aIQfeOODJVheiH/l4Bt9rImL8QO+kl/V1b+DX3Wy67O9xmctX5rKBy1fLoNRXaK7ONllfy/5/7AkfS3mV8Xjq1tfBbmFWjbTNIvaImAPMAZC0OCI6B7pgg8XHU27tdjx91OP62tRGS/4el7l8ZS4buHwl0G2dbaa+ttP75GMpr6F2PIN9018XMKkwPxF4bJDLYGbNcX01G1pcZ80GyGAHzHcCUyRNlrQVcDywcJDLYGbNcX01G1pcZ80GyKB2yYiIjZJOA64FRgDzIuL+blZr+qfeIcLHU27tdjy91sv62oyyv8dlLl+ZywYuX0v1Y51tp/fJx1JeQ+p4BvWmPzMzMzOzocaPxjYzMzMza8ABs5mZmZlZA6UNmNvh8Z6S5klaI+m+QtpYSYskPZT/jmllGZslaZKkGyUtlXS/pE/k9KF6PNtIukPSPfl4/j6nT5Z0ez6eK/ONM9YPylyn632+y0bSCEm/lPTjVpelmqTRkq6S9GB+H9/c6jIVSfpU/t/eJ+kKSdu0ukxlI+m4/B69JKmzatmZue7+WtKRrSpjT5T5O6c7jh/Kp5QBc+HxnkcB+wAnSNqntaXqlUuAaVVpZwDXR8QU4Po8PxRsBD4TEa8DDgZOzf+ToXo8zwOHRMQbgP2BaZIOBr4CnJePZz0ws4VlbBtDoE7X+3yXzSeApa0uRB3nAz+NiD8B3kCJyilpAvBxoDMi9iPdEHd8a0tVSvcBfwHcUkzMdeF4YF/SOe1fc50urSHwndOdS3D8UCqlDJgpPN4zIl4AKo/3HFIi4hZgXVXydODSPH0p8N5BLVQvRcTqiLgrTz9LOhlOYOgeT0TEb/PslvkVwCHAVTl9yBzPEFDqOt3g810akiYC7wa+3eqyVJO0A/AOYC5ARLwQERtaW6rNjAS2lTQSGIXHJ95MRCyNiFpP/psOzI+I5yPiYWAZqU6XWam/c7rj+KF8yhowTwBWFea7KNnJqw92iYjVkD5EwM4tLk+PSeoA3gjczhA+nvzz9t3AGmAR8BtgQ0RszFna6XPXakOmTld9vsvkG8DngJdaXZAa9gDWAt/JXUa+LWm7VheqIiIeBb4GrARWA09HxHWtLdWQMmTqb8FQLHN3huz5tmIoxw9lDZibeiSvDT5JrwL+A/hkRDzT6vL0RUS8GBH7k56GdSDwulrZBrdUbWtI1Omyfr4lHQOsiYglrS5LHSOBA4CLIuKNwO8o0c+ruW/kdGAysBuwnaQPtrZUrSHpZ7kfd/WrUevrkKi/VYZimdtaWb9fmzWoDy7pgXZ+vOcTknaNiNWSdiW1bg4JkrYkfdgvj4irc/KQPZ6KiNgg6SZS36rRkkbmVuZ2+ty1WunrdJ3Pd1m8FXiPpKOBbYAdJH03IsoS9HUBXRFRaZW/ihIFzMBhwMMRsRZA0tXAW4DvtrRULRARh/VitdLX3xqGYpm7M2TPt+0QP5S1hbmdH++5EJiRp2cAP2phWZomSaT+iUsj4uuFRUP1eMZLGp2ntyWdUJcCNwLH5mxD5niGgFLX6Qaf71KIiDMjYmJEdJDeuxtKFCwTEY8DqyTtnZMOBR5oYZGqrQQOljQq/68PpUQ3JQ4BC4HjJW0taTIwBbijxWXqTqm/c3ppqJ5v2yJ+KO2T/nJLyjd45fGe57S4SD0m6QpgKjAOeAI4G/ghsADYnfQlflxEVHfsLx1JbwP+G/gVr/ShPIvUD2koHs/rSTcZjCBdOC6IiC9K2oN0c8hY4JfAByPi+daVtH2UuU7X+3xHxDWtK1VtkqYCfxsRx7S6LEWS9ifdkLgVsBw4JSLWt7ZUr1AaOvL9pDv2fwl8xHV7U5L+HPgXYDywAbg7Io7Myz4PfJj0/n0yIn7SsoI2qczfOd1x/FA+pQ2YzczMzMzKoKxdMszMzMzMSsEBs5mZmZlZAw6YzczMzMwacMBsZmZmZtaAA2YzMzMzswYcMJuZmZmZNeCAeQiS9AFJ1/XzNjskhaQBefpj3vZeA7HtGvu6SdJHBmNfZt2RdImkLw/wPk6WdOtA7sPMbDhzwDwERcTlEXFEq8tRT38FrJJ2lbRQ0mM54O7oe+nMzMxeIem3+aFVvVm3x+e76gYqST+RNKO79frDYO6r3QxIa6J1T9LIiNjY6nKU3EvAT4F/BH4+EDvw/8GstjLUDUkjIuLFVpbB2l9EvKrF+z9qILYraTawV0R8cKD3NRy4hbmfSVoh6UxJD0haL+k7kraRNFVSl6TTJT0OfCfnP0bS3ZI2SPp5fmRzZVuTJF0taa2kpyRdmNM3+fk1X6l+XNJySU9K+qqkhv9bSSMkfS3nXw68u2r5jpLmSlot6VFJX5Y0orD//5H0L5KelvSgpEPzsnOAtwMX5qv2CwubPUzSQ/l9+WZ+vnxdEfFERPwrcGf37/xmXpPL+Kyk6ySNy+WrXNnPlLQSuKEX27Y2kOvio/kz8mtJh0raQtIZkn6T69wCSWML63xf0uP5c3+LpH17sd+adT7v96qqvOdLuiBP162TPdh33e+KQr0+T9I6YHZO/7CkpbneXivpNTldOe+a/H7cK2m/vOzo/B34bC7r3xb2cWuNMu2Vpy+RdJGkayT9DniXpK3zd9VKSU9I+pakbXv6vpsNRRqgbpLWcw6YB8YHgCOBPYHXAl/I6a8GxgKvAWZJOgCYB/wVsBPwb8DCfIIYAfwYeAToACYA8xvs88+BTuAAYDrw4W7K+JfAMcAb83rHVi2/FNgI7JXzHAEUf3Y6CFhOes792cDVksZGxOdJz4w/LSJeFRGnFdY5BngT8AbgfaT3aKCcCJwC7AxsBfxt1fJ3Aq8b4DJYSUnaGzgNeFNEbE/6HKwAPg68l/T52A1YD3yzsOpPgCmkz9VdwOU93G/dOg9cARwtaYecdwSpnnwvr95dnWxWo++KSr3eGThH0nuBs4C/AMaT6vYVOe8RwDtI33GjgfcDT+Vlc4G/yu/tfvTswvRE4Bxge+BW4Ct5H/uTjn0C8Hc92J4NU5JOkfSfhfllkhYU5ldJ2r/GRds3Jf1XvuC7XdKehXUOz41ET+cGoYYNP3md7hqoXu7W0dML17xsX0mLJK3LF5VnSZpGqrvvV2q8uqfGvraQ9AVJj+QL38sk7ZiXVRqXZuSL1Sclfb6n/4O2EhF+9eOLdNL9aGH+aOA3wFTgBWCbwrKLgC9Vrf9r0sn6zcBaYGSNfZwM3FqYD2BaYf5vgOu7KecNVeU8Im9nJLAL8DywbWH5CcCNhf0/Bqiw/A7gpDx9E/CRqv0F8LbC/ALgjCbf05F5/Y4m898EfKHq/fhpnu7I29qj1Z8Vv1r3IgVea4DDgC0L6UuBQwvzuwJ/rFMPR+fP0o7d7OsS4Mt5um6dz9O3Ah/K04cDv8nTzdTJWxuVI+er+12Rt7GyKv9PgJmF+S2A50gX/YcA/wscDGxRtd5K0kXBDlXpm5Uzl2mvwnt1WWGZgN8BexbS3gw83OrPkF/lfwF7ABvy53ZXUgPUo4Vl6/Oy6s/gOuDAfO65HJifl40DniE1MG0JfIp0EfuRbsrxUeBBYBKp0ezGvM+ReflNlW3kOrIR+Fje/7aki/hlpEaekaRGuJ/n/NsDq4HPANvk+YPystnAd6vKUtzXh/N29wBeBVwN/Hte1pHLeHEuwxtI30Gva/X/tVUvtzAPjFWF6UdILVUAayPiD4VlrwE+k3+a3SBpA6lC7Zb/PhLN9yGst896dquxTrFcWwKrC+X6N1KrU8WjkWtVD/b5eGH6OVIFHSjd7WsVNmxFxDLgk6QTyhpJ8yXtRvrs/6DwuV8KvAjskluJzlXqrvEM6eIY0km0WY3qPKTW5BPy9Im80rrcTJ1sVqPviup68Rrg/MI+15GC2AkRcQNwIakF/glJcyqt48D/JTUWPCLpZklv7mX5xgOjgCWFMvw0p5s1FBHLgWdJv068E7gWeFTSn+T5/46Il2qsenVE3JHPv5fn9SF9ph+IiKsi4o/AN9j0XFPP+4BvRMSqiFhHui+nkcci4l8iYmNE/J508fmPEbE0l+kfgP1zK/MxwOMR8c8R8YeIeDYibm+iTJB+Df96RCyPiN8CZwLHV3UD+fuI+H1E3APcQwqchyUHzANjUmF6d1JrLKSrtaJVwDkRMbrwGhURV+Rlu/eg/1K9fdazusY6xXI9D4wrlGuHiCj215wgbdIHudFxltFQKKMNoIj4XkS8jRQUBumn/1XAUVV1cpuIeJQUwE4ntUrvSGqBgSZ+ki1oVOcBvg9MlTSR1HXie4X1uquTzWr0XVHrO+qvqsq7bUT8HCAiLoiIPwX2JXWb+GxOvzMippMC+h+SflGC1Fo8qrJxSa+uUb5iGZ4Efg/sW9j/jtHim7RsSLmZ9AvvO/L0TaRg+Z15vpZ6DS6bNDTlRqNmGl8aNVDV0vSFK6k+/6aJMtQrV7Esj/DKr8wVg9nQVWoOmAfGqZImKt0sdBZwZZ18FwMflXSQku0kvVvS9qQuDquBc3P6NpLe2mCfn5U0RtIk4BMN9lmxAPh4LucY4IzKgohYDVwH/LOkHXI/pz0lvbOw/s55/S0lHUf6qeiavOwJ0k88fSZpG2DrPLt1njfrE0l7Szok9x3+AykoexH4FqnvbuXGtvGSpufVticFrU+Rgr5/6MWuG9V5ImIt6YT+HVK3g6U5vZk62ayefFd8CzhT+eZGpRsPj8vTb8rHsSUpEP4D8KKkrZTGit8xt8I9Q3pvIbVQ7avUb3Qbcv/MenLr38XAeZJ2zvudIMn3HlizKgHz2/P0zXQfMNezSUNTbjSaVD977fXYtIGqlp5cuK4i3S/VzHaqPUYKxovl2kg6h1sVB8wD43ukk9vy/Kr50IKIWEy6+e5CUl+qZaT+S0QaSunPSH0tVwJdpJtq6vkRsAS4G/gv0k03jVxM+nnqHtLNS1dXLf8Q6Wa5B3LZriL1Aau4nXTz05OkG3SOjYjKDT/nA8fmmxMu6KYc3fk98Ns8/WCeN+urrYFzSZ/fx0kXgGeRPrsLgeskPQvcRroRDuAych9IUr24rac7bVTnC75HasX+XlV6d3WyWU1/V0TED0gt7/NzN5T7gMqwVDuQvkfWk96Xp4Cv5WUnASvyOh8FPpi397/AF4GfAQ+R+mx353TS+3Rb3t7PgL2bPFazm4F3kfr/d5FuXJ1Guun2lz3c1n+RLvj+Iv/6+3HSzfzdqdtA1aS6F66kwQFeLemTSgMGbC+p8p31BNCh+qNmXQF8StJkSa8iNQJc2YOuoMOKNu2Gan0laQWpQ/3PBnGfAUzJ/TIHY38nk47xbYOxPzPrH4P9XWFWBpJWk278PiXPLybdU3RUnn+5Xki6BOiKiC/kZVNJN85NzPPTgAtI3Rb+Hfg/pBvlvt1g/yOBr5Iuep8hXVheSLrheKOkm/I+vl3v/CrpJOBzpBbhp4FFEfHhvGw/0sX+AaRfwb4REedK2ol0gbwv6RerA6r2tQXpBsK/JN0weC3wsYhYr/SgsIcrZcz7eXndZt/7duKAuZ85YDazsnLAbGbWO+6S0caUBvj/bY3Xt1pdtorelrHOOr+V9PbBKrtZhaT763wePzDI5Xh7vboxmOUwM2s3bmE2MzMz64PcyPPBGou+GxEfHezyWP9zwGxmZmZm1oC7ZJiZmZmZNdDsQzFaZty4cdHR0dHqYpiVxpIlS56MiFI+6cz11WxTrq9mQ0ej+lr6gLmjo4PFixe3uhhmpSGpu6dEtYzrq9mmXF/Nho5G9dVdMszMzMzMGnDAbGZmZmbWgANmMzMzM7MGHDCbmZmZmTXggNnMzMzMrAEHzGZmZmZmDThgNjMzMzNroPTjMDdj9uy+LTczs95p5vvV38FDl/+/ZolbmM3MzMzMGnDAbGZmZmbWgANmMzMzM7MGHDCbmZmZmTXggNnMzMzMrAEHzGZmZmZmDThgNjMzMzNrwAGzmZmZmVkDDpjN2oykeZLWSLqvKv1jkn4t6X5J/1RIP1PSsrzsyEL6tJy2TNIZg3kMZmZmZdJUwCzpU/kke5+kKyRtI2mypNslPSTpSklb5bxb5/lleXlHYTs1T8xm1q8uAaYVEyS9C5gOvD4i9gW+ltP3AY4H9s3r/KukEZJGAN8EjgL2AU7Iec3MzIadbgNmSROAjwOdEbEfMIJ0gv0KcF5ETAHWAzPzKjOB9RGxF3Bezlf3xNy/h2NmEXELsK4q+a+BcyPi+ZxnTU6fDsyPiOcj4mFgGXBgfi2LiOUR8QIwP+c1MzMbdprtkjES2FbSSGAUsBo4BLgqL78UeG+enp7nycsPlSTqn5jNbOC9Fnh7/tXnZklvyukTgFWFfF05rV76ZiTNkrRY0uK1a9cOQNHN2letLlSSvirpQUn3SvqBpNGFZe5CZdYC3QbMEfEo6efblaRA+WlgCbAhIjbmbMWT6csn2rz8aWAnfAI2a6WRwBjgYOCzwIJ8IasaeaNB+uaJEXMiojMiOsePH99f5TUbLi6hqgsVsAjYLyJeD/wvcCa4C5VZK43sLoOkMaTW4cnABuD7pEpZrXIy7ZcTMDAHoLOzs2YeM+uRLuDqiAjgDkkvAeNy+qRCvonAY3m6XroNE7Nnt7oE7S8ibine65PTrivM3gYcm6df/qUWeFhS8ZfaZRGxHEBSpQvVAwNYdLNhpZkuGYcBD0fE2oj4I3A18BZgdO6iAZueTF8+AeflO5L6UzY6MZvZwPohqRsVkl4LbAU8CSwEjs83604GpgB3AHcCU/LNvVuRWrUWtqTkZsPbh4Gf5Gl3oTJrkWYC5pXAwZJG5Z9wDyVdtd7IK1e9M4Af5emFeZ68/IbcqlXvxGxm/UjSFcAvgL0ldUmaCcwD9sj9JOcDMyK5H1hAqtM/BU6NiBdzd6rTgGuBpcCCnNfMBomkzwMbgcsrSTWyuQuV2SDotktGRNwu6SrgLlLF/SWpu8R/AfMlfTmnzc2rzAX+Pf9UtI7UMkVE3C+pcmLeSD4x9/PxmA17EXFCnUUfrJP/HOCcGunXANf0Y9HMrEmSZgDHAIfmRidwFyqzluk2YAaIiLOBs6uSl1NjlIuI+ANwXJ3t1Dwxm5mZWSJpGnA68M6IeK6waCHwPUlfB3bjlV9qRe5CBTxKaqg6cXBLbdbemgqYzczMequZmweH6w2GuQvVVGCcpC5S49SZwNbAotQTktsi4qONfqmVVOlCNQKY5y5UZv3LAbOZmVmL1OlCNbdGWiW/u1CZtUCzDy4xMzMzMxuWHDCbmZmZmTXggNnMzMzMrAEHzGZmZmZmDThgNjMzMzNrwAGzmZmZmVkDDpjNzMzMzBpwwGxmZmZm1oADZjMzMzOzBhwwm7UZSfMkrZF0X41lfyspJI3L85J0gaRlku6VdEAh7wxJD+XXjME8BjMzszJxwGzWfi4BplUnSpoEHA6sLCQfBUzJr1nARTnvWOBs4CDgQOBsSWMGtNRmZmYl5YDZrM1ExC3AuhqLzgM+B0QhbTpwWSS3AaMl7QocCSyKiHURsR5YRI0g3MzMbDhwwGw2DEh6D/BoRNxTtWgCsKow35XT6qXX2vYsSYslLV67dm0/ltrMzKwcHDCbtTlJo4DPA39Xa3GNtGiQvnlixJyI6IyIzvHjx/e+oGZmZiXlgNms/e0JTAbukbQCmAjcJenVpJbjSYW8E4HHGqSbmZkNOw6YzdpcRPwqInaOiI6I6CAFwwdExOPAQuBDebSMg4GnI2I1cC1whKQx+Wa/I3KamZnZsOOA2azNSLoC+AWwt6QuSTMbZL8GWA4sAy4G/gYgItYBXwLuzK8v5jQzM7NhZ2SrC2Bm/SsiTuhmeUdhOoBT6+SbB8zr18KZmZkNQW5hNjMzMzNrwAGzmZlZi9R6MqeksZIW5adsLqo8NMhP5jRrHQfMZmZmrXMJmz8U6Azg+oiYAlyf58FP5jRrGQfMZmZmLVLnyZzTgUvz9KXAewvpfjKnWQs4YDYzMyuXXfLwjuS/O+d0P5nTrEUcMJuZmQ0NfjKnWYs4YDYzMyuXJ3JXC/LfNTndT+Y0axEHzGZmZuWy8P+3d+/RmlXlne+/v1BKvHMrSFkFKdSKBh0RSQUwJjaRqEA8luZILOLQEulTSRoS06ZPgCSjKaN0YyfGy9FgEyFAD8KlvQzqJESt4K3TR9ACCQIloUQatpRUGS6a0GoKn/PHOze8FLtW7dqX97L39zPGO9615pprvc/ae6+9nj33XHMCkyNdrAOu7it3Zk5pCJy4RJKkIWkzcx4HHJRkgt5oF+cBV7VZOu8GTm7VrwFOojcz58PAqdCbmTPJ5Myc4Myc0pwzYZYkaUg6ZuY8foq6zswpDYldMiRJkqQOJsySJElSBxNmaYHZzVS7f5Lk62063U8m2a9v29ltqt3bk7y6r/yEVrY1yVm7fo4kSYvFtBLmJPsl+Vi74W5J8lLnupdG1sU8cZavTcCLqupngH8EzgZIcgSwFnhh2+fPk+yTZB/gw/Sm4j0COKXVlSRp0ZluC/MHgE9V1QuAFwNbcK57aSRNNdVuVX2mqna21evojdMKval2r6iqH1TVN+k9fX90e22tqjur6ofAFa2uJEmLzh4T5iTPBF4OXAhQVT+sqgdxrntpXL0N+Nu2POupdiVJWuim08L8HGAH8JdJvprko0mehnPdS2MnyR8CO4HLJoumqLZXU+16vUqSFrrpJMxLgKOA86vqJcC/8Fj3i6k41700gtpzA68B3tTGc4U5mGrX61WStNBNJ2GeACaq6vq2/jF6CbRz3UtjIskJwJnAa6vq4b5NG4G1SfZNcji9Zw++TG/GsFVJDk/yZHoPBm4cdNySJI2CPSbMVfVt4J4kz29FxwO34Vz30khqU+1+CXh+kok2ve6HgGcAm5LclOQjAFV1K3AVvWv6U8DpVfVIe0DwDHrX6BbgqlZXkqRFZ7pTY/82cFlrabqT3vz1P4Zz3UsjZzdT7V7YUf9c4Nwpyq+hdz1LkrSoTSthrqqbgNVTbHKue0mSJC1ozvQnSZIkdTBhliRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkqQRlOTfJ7k1yS1JLk/y4226+uuT3JHkyjahGG16+yuTbG3bVw43emlhme5Mf5IkaUCSLAd+Bziiqv53kquAtfRm0n1fVV3Rprg/DTi/vT9QVc9LshZ4D/DGIYUvDdSGDXNTp4sJsyRp6AZxwxtDS4CnJPlX4KnANuAVwK+37ZcAG+glzGvaMsDHgA8lSZt9V9Is2SVDkqQRU1XfAv4UuJteovwQcAPwYFXtbNUmgOVteTlwT9t3Z6t/4K7HTbI+yeYkm3fs2DG/JyEtICbMkiSNmCT702s1Phx4NvA04MQpqk62IKdj22MFVRdU1eqqWr106dK5Clda8OySIS0wSS4CXgNsr6oXtbIDgCuBlcBdwK9V1QNJAnyAXr/Ih4G3VtWNbZ91wB+1w767qi4Z5Hlofi3C7g3j5peBb1bVDoAknwB+HtgvyZLWirwCuLfVnwAOBSaSLAGeBdw/+LClhckWZmnhuRg4YZeys4Brq2oVcG1bh16L1ar2Wk+vL+Rkgn0OcAxwNHBOa/GSNBh3A8cmeWr7w/Z44Dbgc8AbWp11wNVteWNbp23/rP2XpbljwiwtMFX1RZ7YsrSG3gNCtPfX9ZVfWj3X0Wu9Wga8GthUVfdX1QPAJp6YhEuaJ1V1Pb2H924Evkbvfn0BcCbwjiRb6fVRvrDtciFwYCt/W7eYrwAAIABJREFUB4/9USxpDtglQ1ocDqmqbQBVtS3Jwa380QeFmsmHiHZX/gRJ1tNrneawww6b47ClxauqzqH3n55+d9L7r8+udb8PnDyIuKTFyBZmaXHb3YNC03qACHyISJK08JkwS4vDfa2rBe19eyuffFBo0uRDRLsrlyRp0TFhlhaH/geCdn1Q6C3pORZ4qHXd+DTwqiT7t4f9XtXKJEladOzDLC0wSS4HjgMOSjJBrw/kecBVSU6j9/T9ZF/Ha+gNKbeV3rBypwJU1f1J3gV8pdX746pyiCpJ0qJkwiwtMFV1ym42HT9F3QJO381xLgIumsPQJEkaS3bJkCRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6ONOfJEkaug0b5qaONB9sYZYkSZI6mDBLkiRJHUyYpUUkyb9PcmuSW5JcnuTHkxye5PokdyS5MsmTW9192/rWtn3lcKOXJGk4pp0wJ9knyVeT/HVb3+ubbJKzW/ntSV491ycjafeSLAd+B1hdVS8C9gHWAu8B3ldVq4AHgNPaLqcBD1TV84D3tXqSJC06e9PC/HZgS9/6Xt1kkxxB7+b8QuAE4M+T7DO78CXtpSXAU5IsAZ4KbANeAXysbb8EeF1bXtPWaduPT5IBxiotakn2S/KxJF9PsiXJS5MckGRTa6zalGT/VjdJPtgapW5OctSw45cWkmklzElWAL8CfLSth72/ya4BrqiqH1TVN4GtwNFzcRKS9qyqvgX8KXA3vUT5IeAG4MGq2tmqTQDL2/Jy4J62785W/8Bdj5tkfZLNSTbv2LFjfk9CWlw+AHyqql4AvJheo9VZwLWtseratg5wIrCqvdYD5w8+XGnhmm4L8/uB3wd+1NYPZO9vso+WT7HP43gDluZea4laAxwOPBt4Gr2b7K5qcpeObY8VVF1QVauravXSpUvnKlxpUUvyTODlwIUAVfXDqnqQxzdK7dpYdWn1XAfsl2TZgMOWFqw9JsxJXgNsr6ob+ounqLqnm+y0br7gDViaJ78MfLOqdlTVvwKfAH6e3o11ckz2FcC9bXkCOBSgbX8WcP9gQ5YWrecAO4C/bM8PfTTJ04BDqmobQHs/uNWfVqOUDVLSzEynhfllwGuT3AVcQa8rxvvZ+5vso+VT7CNp/t0NHJvkqa2b1PHAbcDngDe0OuuAq9vyxrZO2/7Zqpryj1xJc24JcBRwflW9BPgXHut+MRX/IyTNoz0mzFV1dlWtqKqV9B7a+2xVvYm9v8luBNa2UTQOp9fP6stzdiaSOlXV9fSeK7gR+Bq96/8C4EzgHUm20us+dWHb5ULgwFb+Drpv1pLm1gQw0a5b6F27RwH3TXa1aO/b++rbKCXNk9lMjX0mcEWSdwNf5fE32f/WbrL300uyqapbk1xFr0VrJ3B6VT0yi8+XtJeq6hzgnF2K72SKB3Cr6vvAyYOIS9LjVdW3k9yT5PlVdTuP/UfoNnqNUufxxMaqM5JcARwDPDTZdUPS7O1VwlxVnwc+35b3+iZbVecC5+5tkJIkLUK/DVzW5jm4EziV3n+GrkpyGr1uVpP322uAk+iNQPVwqytpjsymhVmSJM2TqroJWD3FpuOnqFvA6fMelLRIOTW2JEmS1MGEWZIkSepgwixJkiR1MGGWJEmSOvjQnyRJWjA2bJibOlI/W5glSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLC0iSfZL8rEkX0+yJclLkxyQZFOSO9r7/q1uknwwydYkNyc5atjxS5I0DCbM0uLyAeBTVfUC4MXAFuAs4NqqWgVc29YBTgRWtdd64PzBhytJ0vA5DrO0SCR5JvBy4K0AVfVD4IdJ1gDHtWqXAJ8HzgTWAJdWVQHXtdbpZVW1bcChS4Dj60oaHhNmafF4DrAD+MskLwZuAN4OHDKZBFfVtiQHt/rLgXv69p9oZSbMksaaf3xpb5kwS4vHEuAo4Ler6vokH+Cx7hdTyRRl9YRKyXp6XTY47LDD5iJOSRoLJt6Lh32YpcVjApioquvb+sfoJdD3JVkG0N6399U/tG//FcC9ux60qi6oqtVVtXrp0qXzFrwkScNiwiwtElX1beCeJM9vRccDtwEbgXWtbB1wdVveCLyljZZxLPCQ/ZclSYuRXTKkxeW3gcuSPBm4EziV3h/OVyU5DbgbOLnVvQY4CdgKPNzqStLj2C1h9vwajj4TZmkRqaqbgNVTbDp+iroFnD7vQUmSNOLskiFJ0ohKsk+Sryb567Z+eJLr20RDV7b/FpFk37a+tW1fOcy4pYXGFmZJkkbX2+lNMPTMtv4e4H1VdUWSjwCn0ZtU6DTggap6XpK1rd4bhxHwQmEXCPUzYZYkaQQlWQH8CnAu8I4kAV4B/HqrcgmwgV7CvKYtQ28EnA8lSetaNXQmnxp3dsmQJGk0vR/4feBHbf1A4MGq2tnWJycTgr6Jhtr2h1r9x0myPsnmJJt37Ngxn7FLC4oJsyRJIybJa4DtVXVDf/EUVWsa2x4rcNx0aUbskiFJ0uh5GfDaJCcBP06vD/P7gf2SLGmtyP2TCU1ONDSRZAnwLOD+wYctLUy2MEuSNGKq6uyqWlFVK4G1wGer6k3A54A3tGq7TjQ0OQHRG1r9kei/LC0EJsySJI2PM+k9ALiVXh/lC1v5hcCBrfwdwFlDik9akOySIUnSCKuqzwOfb8t3AkdPUef7PDZLpzSvFuPMhCbMkiRJGkmjknjbJUOSJEnqYMIsSZIkdTBhliRJkjrssQ9zkkOBS4GfoDfb0AVV9YEkBwBXAiuBu4Bfq6oH2tSdHwBOAh4G3lpVN7ZjrQP+qB363VV1ydyejqQ9SbIPsBn4VlW9JsnhwBXAAcCNwJur6odJ9qV37f8s8E/AG6vqriGFrb0wKn3+JGmhmM5DfzuB36uqG5M8A7ghySbgrcC1VXVekrPoDWFzJnAisKq9jqE3x/0xLcE+B1hNb/ahG5JsrKoH5vqkJHV6O7CF3kQIAO8B3ldVVyT5CHAavev2NOCBqnpekrWt3huHEbAkaeEZpz/u95gwV9U2YFtb/l6SLfTmrF8DHNeqXUJvyJszW/mlbcD065Lsl2RZq7upqu4HaEn3CcDlc3g+kjokWQH8CnAuvbFcA7wC+PVW5RJgA72EeU1bBvgY8KEkcTIESdKejFMyPB17NaxckpXAS4DrgUNaMk1VbUtycKu2HLinb7eJVra78qk+Zz2wHuCwww7bmxAldXs/8PvAM9r6gcCDbZpdePx1+eg1W1U7kzzU6n+n/4Ber5I0/xbj2MejZNoP/SV5OvBx4Her6rtdVacoq47yJxZWXVBVq6tq9dKlS6cboqQOSV4DbK+qG/qLp6ha09j2WIHXqyRpgZtWwpzkSfSS5cuq6hOt+L7W1YL2vr2VTwCH9u2+Ari3o1zSYLwMeG2Su+g95PcKei3O+yWZ/G9T/3X56DXbtj8LuH+QAUuSNAr2mDC3Po4XAluq6s/6Nm0E1rXldcDVfeVvSc+xwEOt68angVcl2T/J/sCrWpmkAaiqs6tqRVWtBNYCn62qNwGfA97Qqu16LU9e429o9e2/LEladKbTh/llwJuBryW5qZX9AXAecFWS04C7eWwO+2voDSm3ld6wcqcCVNX9Sd4FfKXV++PJBwAlDdWZwBVJ3g18ld4fyLT3/5ZkK72W5bVDik+SpKGazigZf8/UfRkBjp+ifgGn7+ZYFwEX7U2AkuZeVX2e3sg2VNWdwNFT1Pk+j/0hLEkacT4YOH/2apQMSZKkYTHZmz2T6pkxYZYkSZonJp8Lw7SHlZMkSZIWI1uYJUkLhv9uljQfbGGWJEmSOpgwS5I0YpIcmuRzSbYkuTXJ21v5AUk2Jbmjve/fypPkg0m2Jrk5yVHDPQNpYTFhliRp9OwEfq+qfho4Fjg9yRHAWcC1VbUKuLatA5wIrGqv9cD5gw9ZWrhMmCVJGjFVta2qbmzL3wO2AMuBNcAlrdolwOva8hrg0uq5jt6U98sGHLa0YJkwS5I0wpKsBF4CXA8cUlXboJdUAwe3asuBe/p2m2hlkuaACbMkSSMqydOBjwO/W1Xf7ao6RVlNcbz1STYn2bxjx465ClNa8EyYJUkaQUmeRC9ZvqyqPtGK75vsatHet7fyCeDQvt1XAPfuesyquqCqVlfV6qVLl85f8NICY8IsSdKISRLgQmBLVf1Z36aNwLq2vA64uq/8LW20jGOBhya7bkiaPRNmaZFwmCpprLwMeDPwiiQ3tddJwHnAK5PcAbyyrQNcA9wJbAX+Avh3Q4hZWrCc6U9aPCaHqboxyTOAG5JsAt5Kb5iq85KcRW+YqjN5/DBVx9AbpuqYoUQuLTJV9fdM3S8Z4Pgp6hdw+rwGJS1itjBLi4TDVEmSNDO2MEuLUNcwVUn2NEzV4/pFJllPb6IEDjvssHmNW7Bhw7AjkKTFxxZmaZGZ62GqfOpekrTQ2cIsLSJdw1S11uW9HqZKkrSw+J+sJ7KFWVokHKZKkqSZsYVZWjwmh6n6WpKbWtkf0BuW6qokpwF3Aye3bdcAJ9Ebpuph4NTBhitJ0mgwYZYWCYepkiRpZuySIUmSJHWwhVmStKhM54EmH3qS1M8WZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHRxWTpJGhEOZSdJosoVZkiRJ6mDCLEmSJHWwS4YkDYhdLiRpPA28hTnJCUluT7I1yVmD/nxJ0+f1Ko0Xr1lpfgy0hTnJPsCHgVcCE8BXkmysqtsGGYekPfN61WI2nf8GjNp/DLxmpfkz6C4ZRwNbq+pOgCRXAGuAeb2Yx/EXnzQChnK9jit/h2gEeM1K82TQCfNy4J6+9QngmAHHMCVvdt38+ixK83K9+rMkzZuRvcdK427QCXOmKKsnVErWA+vb6j8nuX0Pxz0I+M4sYxslI3c+73znrHYfufOZpWGfz08O6HPm63odRcP+ns6GsQ/HQe9857RiH9T1CtO4Zhfx/dXzGB1DOYdp5jG7vV4HnTBPAIf2ra8A7t21UlVdAFww3YMm2VxVq2cf3mjwfEbbQjufDvNyvY6icf6eGvtwjGjse7xmF+v91fMYHeN6DoMeJeMrwKokhyd5MrAW2DjgGCRNj9erNF68ZqV5MtAW5qrameQM4NPAPsBFVXXrIGOQND1er9J48ZqV5s/AJy6pqmuAa+b4sGP97+ApeD6jbaGdz27N0/U6isb5e2rswzGSsc/DNTuS5zkDnsfoGMtzSNUTnuGRJEmS1Ax8pj9JkiRpnIx9wjyO04AmuSjJ9iS39JUdkGRTkjva+/6tPEk+2M7v5iRHDS/yJ0pyaJLPJdmS5NYkb2/lY3k+AEl+PMmXk/xDO6d3tvLDk1zfzunK9lANSfZt61vb9pXDjF89c3WdJVnX6t+RZN0Ixv6CJF9K8oMk/2GX4wz89+Nexv6m9vW+Ocn/l+TFYxT7mhb3TUk2J/mFvn0G/jMzH8bp/roQ7qsL5X66YO+hVTW2L3oPNXwDeA7wZOAfgCOGHdc04n45cBRwS1/ZfwHOastnAe9pyycBf0tvfM1jgeuHHf8u57IMOKotPwP4R+CIcT2fFmOAp7flJwHXt1ivAta28o8Av9WW/x3wkba8Frhy2Ofga26uM+AA4M72vn9b3n/EYj8Y+DngXOA/9NUfyu/HvYz95ye/nsCJfV/3cYj96TzWrfFngK8P82dmHr4WY3V/nYvrfdgvFsj9lAV6Dx16ALP8prwU+HTf+tnA2cOOa5qxr9zlwr4dWNaWlwG3t+X/CpwyVb1RfAFXA69cQOfzVOBGerNlfQdY0sof/dmj90T6S9vyklYvw47d1+yvM+AU4L/2lT+u3ijE3rd9A49PmIf2+3FvY2/l+wPfGtPYXwpsactD+5mZ46/D2N1fZ3u9Dzv+Kc5n7O+nLKB76Lh3yZhqGtDlQ4pltg6pqm0A7f3gVj4259j+jfISen9NjvX5JNknyU3AdmATvZaWB6tqZ6vSH/ej59S2PwQcONiINU17+3M5Sj+vu4t9d8Yt9tPotZbBmMSe5PVJvg78DfC2VjxKsc/GQjiPsb0Pjfv9dCHeQ8c9YZ7W1L1jbizOMcnTgY8Dv1tV3+2qOkXZyJ1PVT1SVUfSmynraOCnp6rW3sfinNRpd9/Dcf7ejk3sSX6JXsJ85mTRFNVGLvaq+mRVvQB4HfCuVjwWsU/DQjmPqYz0uS2E++lCvIeOe8I8ral7x8R9SZYBtPftrXzkzzHJk+hd3JdV1Sda8dieT7+qehD4PL3+V/slmRy7vD/uR8+pbX8WcP9gI9U07e3P5Sj9vO4u9t0Zi9iT/AzwUWBNVf1TKx6L2CdV1ReB5yY5iNGKfTYWwnmM3X1ood1PF9I9dNwT5oU0DehGYPJp6nX0+i5Nlr+lPQ17LPDQ5L9mRkGSABfS67/3Z32bxvJ8AJIsTbJfW34K8MvAFuBzwBtatV3PafJc3wB8tlpnLI2cvf25/DTwqiT7tyfTX9XKhmF3se/OKP1+nDL2JIcBnwDeXFX/2Fd/HGJ/Xvv9Rxud4MnAPzFaPzOzMUrfg5kaq/vQQrmfLth76LA7Uc/2Re8p0X+k1z/mD4cdzzRjvhzYBvwrvb+sTqPXX+da4I72fkCrG+DD7fy+Bqwedvy7nMsv0PvXyc3ATe110rieT4vxZ4CvtnO6BfiPrfw5wJeBrcB/B/Zt5T/e1re27c8Z9jn4mrvrjF7f1K3tdeoIxv4Trc53gQfb8jPbtoH/ftzL2D8KPND3u2Nz33FGPfYzgVtb3F8CfmGYPzPz9PUYm/vrXF3vQz6HBXE/ZYHeQ53pT5IkSeow7l0yJEmSpHllwixJkiR1MGGWJEmSOpgwS5IkSR1MmCVJkqQOJsySJElSBxNmSZIkqYMJ8wKQ5J+TPGeG+34+yb+d65jmWpK3Jvn7YcchSZIWnyV7rqJRV1VPH3YMkiRJC5UtzJIkSVIHE+YRluTUJP9v3/rWJFf1rd+T5MgkleR5reziJB9O8jdJvpfk+iTP7dvnlUm+nuShJB+iNxf9nuJ4XpIvtH2+k+TKvm2V5HeS3Nm2/UmSH+vb/rYkW5I8kOTTSX6yb9sLkmxKcn+S25P8Wt+2A5NsTPLdJF8GHj0HSZKkQTJhHm1fAH4xyY8lWQY8CXgZQOuz/HTg5in2OwV4J7A/sBU4t+1zEPBx4I+Ag4BvTB5vD94FfKYdbwXw/+yy/fXAauAoYA3wtvZ5rwP+APhVYCnwP4DL27anAZuAvwIObjH/eZIXtmN+GPg+sKwd723TiFOSJGnOmTCPsKq6E/gecCTwb4BPA99K8oK2/j+q6kdT7PqJqvpyVe0ELmv7A5wE3FZVH6uqfwXeD3x7GqH8K/CTwLOr6vtVtevDd++pqvur6u52zFNa+W8A/7mqtrRY/hNwZGtlfg1wV1X9ZVXtrKob6SXzb0iyD/B/Av+xqv6lqm4BLplGnJIkSXPOhHn0fQE4Dnh5W/48vWT537T1qfQnwQ/Ta4kGeDZwz+SGqqr+9Q6/T6/rxpeT3Jpk19be/mP8r/Y50EuyP5DkwSQPAve34yxv246Z3Na2vwn4CXqt0UumOK4kSdLAOUrG6PsC8H8Ah9NroZ1MLF8KfGgvj7UNOHRyJUn613enqr4N/F9tn18A/i7JF6tqa6tyKHBrWz4MuLct3wOcW1WX7XrM1sr8hap65RTb9gF2tuN+ve+4kiRJA2cL8+j7AvBLwFOqaoJeP+ATgAOBr+7lsf4GeGGSX02yBPgdei26nZKcnGRFW30AKOCRvir/d5L9kxwKvB2YfCjwI8DZk/2Skzwryclt218DP5XkzUme1F4/l+Snq+oR4BPAhiRPTXIEsG4vz1WSJGlOmDCPuKr6R+Cf6SXKVNV3gTuB/9kSy7051neAk4HzgH8CVgH/cxq7/hxwfZJ/BjYCb6+qb/Ztvxq4AbiJXlJ+Yfu8TwLvAa5I8l3gFuDEtu17wKuAtfRapL/d6u7bjnkGva4k3wYuBv5yb85VkiRprqTXjVWamSQFrOrrniFJkrSg2MIsSZIkdTBhFgBJPpLkn6d4fWTYsUmSJA2TXTIkSZKkDrYwS5IkSR1Gfhzmgw46qFauXDnsMKSRccMNN3ynqpYOOw5JkhaLkU+YV65cyebNm4cdhjQykjjroSRJA2SXDEmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA57HIc5yUXAa4DtVfWiVnYl8PxWZT/gwao6MslKYAtwe9t2XVX9ZtvnZ4GLgacA1wBvrwU4L/eGDXNTR5IkSaNhOhOXXAx8CLh0sqCq3ji5nOS9wEN99b9RVUdOcZzzgfXAdfQS5hOAv937kCVJkqTB2WOXjKr6InD/VNuSBPg14PKuYyRZBjyzqr7UWpUvBV639+FKkiRJgzXbPsy/CNxXVXf0lR2e5KtJvpDkF1vZcmCir85EK5tSkvVJNifZvGPHjlmGKEmSJM3cbBPmU3h86/I24LCqegnwDuCvkjwTyBT77rb/clVdUFWrq2r10qVLZxmiJEmSNHPT6cM8pSRLgF8FfnayrKp+APygLd+Q5BvAT9FrUV7Rt/sK4N6ZfrYkSZI0KLNpYf5l4OtV9WhXiyRLk+zTlp8DrALurKptwPeSHNv6Pb8FuHoWny1JkiQNxB4T5iSXA18Cnp9kIslpbdNanviw38uBm5P8A/Ax4DeravKBwd8CPgpsBb6BI2RIkiRpDOyxS0ZVnbKb8rdOUfZx4OO7qb8ZeNFexidJkiQNlTP9SZIkSR1MmCVJkqQOJsySJElSBxNmSZIkqYMJsyRJktTBhFmSJEnqYMIsSZIkdTBhliRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI67DFhTnJRku1Jbukr25DkW0luaq+T+radnWRrktuTvLqv/IRWtjXJWXN/KpIkSdLcm04L88XACVOUv6+qjmyvawCSHAGsBV7Y9vnzJPsk2Qf4MHAicARwSqsrSZIkjbQle6pQVV9MsnKax1sDXFFVPwC+mWQrcHTbtrWq7gRIckWre9teRyxJkiQN0Gz6MJ+R5ObWZWP/VrYcuKevzkQr2125JEmSNNJmmjCfDzwXOBLYBry3lWeKutVRPqUk65NsTrJ5x44dMwxRkiRJmr0ZJcxVdV9VPVJVPwL+gse6XUwAh/ZVXQHc21G+u+NfUFWrq2r10qVLZxKiJEmSNCdmlDAnWda3+npgcgSNjcDaJPsmORxYBXwZ+AqwKsnhSZ5M78HAjTMPW5IkSRqMPT70l+Ry4DjgoCQTwDnAcUmOpNet4i7gNwCq6tYkV9F7mG8ncHpVPdKOcwbwaWAf4KKqunXOz0aSJEmaY9MZJeOUKYov7Kh/LnDuFOXXANfsVXSSJEnSkDnTnyRJktTBhFmSJEnqYMIsSZIkdTBhliRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA4mzJIkSVIHE2ZJkiSpgwmzJEmS1GGPCXOSi5JsT3JLX9mfJPl6kpuTfDLJfq18ZZL/neSm9vpI3z4/m+RrSbYm+WCSzM8pSZIkSXNnyTTqXAx8CLi0r2wTcHZV7UzyHuBs4My27RtVdeQUxzkfWA9cB1wDnAD87QzjHmsbNsxNHUmSJM2/PbYwV9UXgft3KftMVe1sq9cBK7qOkWQZ8Myq+lJVFb3k+3UzC1mSJEkanLnow/w2Ht9SfHiSryb5QpJfbGXLgYm+OhOtbEpJ1ifZnGTzjh075iBESZIkaWZmlTAn+UNgJ3BZK9oGHFZVLwHeAfxVkmcCU/VXrt0dt6ouqKrVVbV66dKlswlRkiRJmpXp9GGeUpJ1wGuA41s3C6rqB8AP2vINSb4B/BS9FuX+bhsrgHtn+tmSJEnSoMyohTnJCfQe8nttVT3cV740yT5t+TnAKuDOqtoGfC/JsW10jLcAV886ekmSJGme7bGFOcnlwHHAQUkmgHPojYqxL7CpjQ53XVX9JvBy4I+T7AQeAX6zqiYfGPwteiNuPIVen+dFOUKGJEmSxsseE+aqOmWK4gt3U/fjwMd3s20z8KK9ik6SJEkaMmf6kyRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA4mzJIkSVIHE2ZJkiSpgwmzJEmS1MGEWZIkSepgwixJkiR1MGGWJEmSOiyZTqUkFwGvAbZX1Yta2QHAlcBK4C7g16rqgSQBPgCcBDwMvLWqbmz7rAP+qB323VV1yVycxIYNs9suSZIk7c50W5gvBk7Ypews4NqqWgVc29YBTgRWtdd64Hx4NME+BzgGOBo4J8n+swlekiRJmm/TSpir6ovA/bsUrwEmW4gvAV7XV35p9VwH7JdkGfBqYFNV3V9VDwCbeGISLkmSJI2U2fRhPqSqtgG094Nb+XLgnr56E61sd+VPkGR9ks1JNu/YsWMWIUqSJEmzMx8P/WWKsuoof2Jh1QVVtbqqVi9dunROg5MkSZL2xrQe+tuN+5Isq6ptrcvF9lY+ARzaV28FcG8rP26X8s/P4vPn1HQeDPThQUmSpMVnNgnzRmAdcF57v7qv/IwkV9B7wO+hllR/GvhPfQ/6vQo4exafP3AmzJIkSYvPdIeVu5xe6/BBSSbojXZxHnBVktOAu4GTW/Vr6A0pt5XesHKnAlTV/UneBXyl1fvjqtr1QUJJkiRppEwrYa6qU3az6fgp6hZw+m6OcxFRmGLXAAAJVElEQVRw0bSjkyRJkobMmf4kSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHWYzNfbYcEprSZIkzZQtzJIkSVIHE2ZJkiSpgwmzJEmS1MGEWZIkSepgwixJkiR1MGGWJEmSOpgwS5IkSR1mnDAneX6Sm/pe303yu0k2JPlWX/lJffucnWRrktuTvHpuTkGSJEmaPzOeuKSqbgeOBEiyD/At4JPAqcD7qupP++snOQJYC7wQeDbwd0l+qqoemWkMkiRJ0nybqy4ZxwPfqKr/1VFnDXBFVf2gqr4JbAWOnqPPlyRJkubFXCXMa4HL+9bPSHJzkouS7N/KlgP39NWZaGWSJEnSyJp1wpzkycBrgf/eis4Hnkuvu8Y24L2TVafYvXZzzPVJNifZvGPHjtmGKEmSJM3YXLQwnwjcWFX3AVTVfVX1SFX9CPgLHut2MQEc2rffCuDeqQ5YVRdU1eqqWr106dI5CFGSJEmamblImE+hrztGkmV9214P3NKWNwJrk+yb5HBgFfDlOfh8SZIkad7MeJQMgCRPBV4J/EZf8X9JciS97hZ3TW6rqluTXAXcBuwETneEDEmSJI26WSXMVfUwcOAuZW/uqH8ucO5sPlOSJEkaJGf6kyRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA4mzJIkSVIHE2ZJkiSpgwmzJEmS1MGEWZIkSepgwixJkiR1MGGWJEmSOsw6YU5yV5KvJbkpyeZWdkCSTUnuaO/7t/Ik+WCSrUluTnLUbD9fkiRJmk9L5ug4v1RV3+lbPwu4tqrOS3JWWz8TOBFY1V7HAOe3d82TDRvmpo4kSdJiNV9dMtYAl7TlS4DX9ZVfWj3XAfslWTZPMUiSJEmzNhcJcwGfSXJDkvWt7JCq2gbQ3g9u5cuBe/r2nWhlj5NkfZLNSTbv2LFjDkKUJEmSZmYuumS8rKruTXIwsCnJ1zvqZoqyekJB1QXABQCrV69+wnZJkiRpUGbdwlxV97b37cAngaOB+ya7WrT37a36BHBo3+4rgHtnG4MkSZI0X2aVMCd5WpJnTC4DrwJuATYC61q1dcDVbXkj8JY2WsaxwEOTXTckSZKkUTTbLhmHAJ9MMnmsv6qqTyX5CnBVktOAu4GTW/1rgJOArcDDwKmz/PwFy9EtJEmSRsOsEuaquhN48RTl/wQcP0V5AafP5jMlSZKkQXKmP0mSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA4mzJIkSVIHE2ZJkiSpgwmzJEmS1MGEWZIkSeqwZNgBaOY2bBh2BJIkSQufLcySJElSBxNmSZIkqYMJsyRJktTBhFmSJEnqYMIsSZIkdZhxwpzk0CSfS7Ilya1J3t7KNyT5VpKb2uukvn3OTrI1ye1JXj0XJyBJkiTNp9kMK7cT+L2qujHJM4Abkmxq295XVX/aXznJEcBa4IXAs4G/S/JTVfXILGKQJEmS5tWMW5iraltV3diWvwdsAZZ37LIGuKKqflBV3wS2AkfP9PMlSZKkQZiTPsxJVgIvAa5vRWckuTnJRUn2b2XLgXv6dptgNwl2kvVJNifZvGPHjrkIUZIkSZqRWSfMSZ4OfBz43ar6LnA+8FzgSGAb8N7JqlPsXlMds6ouqKrVVbV66dKlsw1RkiRJmrFZJcxJnkQvWb6sqj4BUFX3VdUjVfUj4C94rNvFBHBo3+4rgHtn8/mSJEnSfJvNKBkBLgS2VNWf9ZUv66v2euCWtrwRWJtk3ySHA6uAL8/08yVJkqRBmM0oGS8D3gx8LclNrewPgFOSHEmvu8VdwG8AVNWtSa4CbqM3wsbpjpAxPjZsmJs6kiRJ42bGCXNV/T1T90u+pmOfc4FzZ/qZkiRJ0qA5058kSZLUYTZdMrRA2JVCkiRp92xhliRJkjqYMEuSJEkdTJglSZKkDibMkiRJUgcTZkmSJKmDCbMkSZLUwYRZkiRJ6mDCLEmSJHUwYZYkSZI6mDBLkiRJHUyYJUmSpA5Lhh2AFpcNG+amjiRJ0qCYMGvOmOhKkqSFyC4ZkiRJUgcTZkmSJKnDwBPmJCckuT3J1iRnDfrzJUmSpL0x0D7MSfYBPgy8EpgAvpJkY1XdNsg4NP58eFCSJA3KoB/6OxrYWlV3AiS5AlgDmDDrUYNMdOcq8TaBlyRp4UpVDe7DkjcAJ1TVv23rbwaOqaozdqm3HljfVp8P3L6HQx8EfGeOwx1FnufCMtPz/MmqWjrXwUiSpKkNuoU5U5Q9IWOvqguAC6Z90GRzVa2eTWDjwPNcWBbLeUqSNO4G/dDfBHBo3/oK4N4BxyBJkiRN26AT5q8Aq5IcnuTJwFpg44BjkCRJkqZtoF0yqmpnkjOATwP7ABdV1a1zcOhpd98Yc57nwrJYzlOSpLE20If+JEmSpHHjTH+SJElSBxNmSZIkqcNYJ8yLZZrtJHcl+VqSm5JsHnY8cynJRUm2J7mlr+yAJJuS3NHe9x9mjHNhN+e5Icm32vf1piQnDTNGSZI0tbFNmPum2T4ROAI4JckRw41qXv1SVR25AMftvRg4YZeys4Brq2oVcG1bH3cX88TzBHhf+74eWVXXDDgmSZI0DWObMNM3zXZV/RCYnGZbY6Sqvgjcv0vxGuCStnwJ8LqBBjUPdnOekiRpDIxzwrwcuKdvfaKVLUQFfCbJDW3a8IXukKraBtDeDx5yPPPpjCQ3ty4bY9/1RJKkhWicE+ZpTbO9QLysqo6i1/3k9CQvH3ZAmhPnA88FjgS2Ae8dbjiSJGkq45wwL5pptqvq3va+Hfgkve4oC9l9SZYBtPftQ45nXlTVfVX1SFX9CPgLFv73VZKksTTOCfOimGY7ydOSPGNyGXgVcEv3XmNvI7CuLa8Drh5iLPNm8o+C5vUs/O+rJEljaaBTY8+leZxme9QcAnwyCfS+X39VVZ8abkhzJ8nlwHHAQUkmgHOA84CrkpwG3A2cPLwI58ZuzvO4JEfS60p0F/AbQwtQkiTtllNjS5IkSR3GuUuGJEmSNO9MmCVJkqQOJsySJElSBxNmSZIkqYMJsyRJktTBhFmSJEnqYMIsSZIkdfj/AUkQW1SBHcpGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 20\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "index = 1\n",
    "for i in testing_site_id.columns:\n",
    "    plt.subplot((len(testing_site_id.columns)+2)//3, 3, index)\n",
    "    plt.title(i)\n",
    "    n, bins, patches = plt.hist(testing_site_id[i], num_bins, facecolor='blue', alpha=0.5)\n",
    "    index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precip_depth_1_hr now doesn't have any useful info\n",
    "testing_site_id = testing_site_id.drop('precip_depth_1_hr', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's fit normal distribution on our data\n",
    "num_bins = 20\n",
    "\n",
    "\n",
    "def get_in_columns(column, testing_site_id):\n",
    "    y, x, patches = plt.hist(testing_site_id[column], num_bins, facecolor='blue', alpha=0.5)\n",
    "    x = np.array(x[:-1], dtype='float32')\n",
    "    y = np.array(y, dtype='float32')\n",
    "\n",
    "    x = ((x - x.mean())/x.max())*10\n",
    "    y /= y.max()\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "x, y = get_in_columns('air_temperature', testing_site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DestributionLayer(layers.Layer):\n",
    "    def __init__(self, mu=0., st=1.):\n",
    "        super(DestributionLayer, self).__init__()\n",
    "        \n",
    "        self.mu_var = mu\n",
    "        self.st_var = st\n",
    "        \n",
    "        self.trainable = True\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(shape=(input_shape[-1]),\n",
    "                             initializer=tf.keras.initializers.Constant(self.mu_var),\n",
    "                             trainable=True)\n",
    "        \n",
    "        self.st = self.add_weight(shape=(input_shape[-1]),\n",
    "                             initializer=tf.keras.initializers.Constant(self.st_var),\n",
    "                             trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.math.exp(-(inputs - self.mu)**2 / (2*self.st)) / tf.math.sqrt(2*np.pi*self.st)\n",
    "    \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples\n",
      "Epoch 1/800\n",
      "20/20 [==============================] - 1s 33ms/sample - loss: 0.1817\n",
      "Epoch 2/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1703\n",
      "Epoch 3/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1631\n",
      "Epoch 4/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1575\n",
      "Epoch 5/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1529\n",
      "Epoch 6/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1489\n",
      "Epoch 7/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1453\n",
      "Epoch 8/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.1421\n",
      "Epoch 9/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1391\n",
      "Epoch 10/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1363\n",
      "Epoch 11/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.1337\n",
      "Epoch 12/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.1313\n",
      "Epoch 13/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.1289\n",
      "Epoch 14/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1267\n",
      "Epoch 15/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1245\n",
      "Epoch 16/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1225\n",
      "Epoch 17/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.1205\n",
      "Epoch 18/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1185\n",
      "Epoch 19/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.1166\n",
      "Epoch 20/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1148\n",
      "Epoch 21/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1129\n",
      "Epoch 22/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1112\n",
      "Epoch 23/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1094\n",
      "Epoch 24/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1077\n",
      "Epoch 25/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1061\n",
      "Epoch 26/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.1044\n",
      "Epoch 27/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.1028\n",
      "Epoch 28/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.1012\n",
      "Epoch 29/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0996\n",
      "Epoch 30/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0981\n",
      "Epoch 31/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0966\n",
      "Epoch 32/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0951\n",
      "Epoch 33/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0936\n",
      "Epoch 34/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0921\n",
      "Epoch 35/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0907\n",
      "Epoch 36/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0893\n",
      "Epoch 37/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0879\n",
      "Epoch 38/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0865\n",
      "Epoch 39/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0852\n",
      "Epoch 40/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0838\n",
      "Epoch 41/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0825\n",
      "Epoch 42/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0812\n",
      "Epoch 43/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0800\n",
      "Epoch 44/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0787\n",
      "Epoch 45/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0775\n",
      "Epoch 46/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0763\n",
      "Epoch 47/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0751\n",
      "Epoch 48/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0740\n",
      "Epoch 49/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0728\n",
      "Epoch 50/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0717\n",
      "Epoch 51/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0706\n",
      "Epoch 52/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0696\n",
      "Epoch 53/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0685\n",
      "Epoch 54/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0675\n",
      "Epoch 55/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0665\n",
      "Epoch 56/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0655\n",
      "Epoch 57/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0646\n",
      "Epoch 58/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0637\n",
      "Epoch 59/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0627\n",
      "Epoch 60/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0618\n",
      "Epoch 61/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0610\n",
      "Epoch 62/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0601\n",
      "Epoch 63/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0593\n",
      "Epoch 64/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0585\n",
      "Epoch 65/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0577\n",
      "Epoch 66/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0569\n",
      "Epoch 67/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0561\n",
      "Epoch 68/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0554\n",
      "Epoch 69/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0546\n",
      "Epoch 70/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0539\n",
      "Epoch 71/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0532\n",
      "Epoch 72/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0525\n",
      "Epoch 73/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0519\n",
      "Epoch 74/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0512\n",
      "Epoch 75/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0506\n",
      "Epoch 76/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0500\n",
      "Epoch 77/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0493\n",
      "Epoch 78/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0488\n",
      "Epoch 79/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0482\n",
      "Epoch 80/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0476\n",
      "Epoch 81/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0471\n",
      "Epoch 82/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0465\n",
      "Epoch 83/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0460\n",
      "Epoch 84/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0455\n",
      "Epoch 85/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0450\n",
      "Epoch 86/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0445\n",
      "Epoch 87/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0440\n",
      "Epoch 88/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0435\n",
      "Epoch 89/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0431\n",
      "Epoch 90/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0426\n",
      "Epoch 91/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0422\n",
      "Epoch 92/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0418\n",
      "Epoch 93/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0414\n",
      "Epoch 94/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0410\n",
      "Epoch 95/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0406\n",
      "Epoch 96/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0402\n",
      "Epoch 97/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0395\n",
      "Epoch 99/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0391\n",
      "Epoch 100/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0388\n",
      "Epoch 101/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0384\n",
      "Epoch 102/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0381\n",
      "Epoch 103/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0378\n",
      "Epoch 104/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0374\n",
      "Epoch 105/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0371\n",
      "Epoch 106/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0368\n",
      "Epoch 107/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0365\n",
      "Epoch 108/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0363\n",
      "Epoch 109/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0360\n",
      "Epoch 110/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0357\n",
      "Epoch 111/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0354\n",
      "Epoch 112/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0352\n",
      "Epoch 113/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0349\n",
      "Epoch 114/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0347\n",
      "Epoch 115/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0344\n",
      "Epoch 116/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0342\n",
      "Epoch 117/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0339\n",
      "Epoch 118/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0337\n",
      "Epoch 119/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0335\n",
      "Epoch 120/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0333\n",
      "Epoch 121/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0330\n",
      "Epoch 122/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0328\n",
      "Epoch 123/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0326\n",
      "Epoch 124/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0324\n",
      "Epoch 125/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0322\n",
      "Epoch 126/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0320\n",
      "Epoch 127/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0318\n",
      "Epoch 128/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0316\n",
      "Epoch 129/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0314\n",
      "Epoch 130/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0312\n",
      "Epoch 131/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0310\n",
      "Epoch 132/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0309\n",
      "Epoch 133/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0307\n",
      "Epoch 134/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0305\n",
      "Epoch 135/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0303\n",
      "Epoch 136/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0302\n",
      "Epoch 137/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0300\n",
      "Epoch 138/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0298\n",
      "Epoch 139/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0297\n",
      "Epoch 140/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0295\n",
      "Epoch 141/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0293\n",
      "Epoch 142/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0292\n",
      "Epoch 143/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0290\n",
      "Epoch 144/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0289\n",
      "Epoch 145/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0287\n",
      "Epoch 146/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0286\n",
      "Epoch 147/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0284\n",
      "Epoch 148/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0283\n",
      "Epoch 149/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0281\n",
      "Epoch 150/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0280\n",
      "Epoch 151/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0279\n",
      "Epoch 152/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0277\n",
      "Epoch 153/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0276\n",
      "Epoch 154/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0275\n",
      "Epoch 155/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0273\n",
      "Epoch 156/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0272\n",
      "Epoch 157/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0271\n",
      "Epoch 158/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0270\n",
      "Epoch 159/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0269\n",
      "Epoch 160/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0267\n",
      "Epoch 161/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0266\n",
      "Epoch 162/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0265\n",
      "Epoch 163/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0264\n",
      "Epoch 164/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0263\n",
      "Epoch 165/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0262\n",
      "Epoch 166/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0261\n",
      "Epoch 167/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0260\n",
      "Epoch 168/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0258\n",
      "Epoch 169/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0257\n",
      "Epoch 170/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0256\n",
      "Epoch 171/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0255\n",
      "Epoch 172/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0254\n",
      "Epoch 173/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0253\n",
      "Epoch 174/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0252\n",
      "Epoch 175/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0251\n",
      "Epoch 176/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0250\n",
      "Epoch 177/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0249\n",
      "Epoch 178/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0248\n",
      "Epoch 179/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0248\n",
      "Epoch 180/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0247\n",
      "Epoch 181/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0246\n",
      "Epoch 182/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0245\n",
      "Epoch 183/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0244\n",
      "Epoch 184/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0243\n",
      "Epoch 185/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0242\n",
      "Epoch 186/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0241\n",
      "Epoch 187/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0240\n",
      "Epoch 188/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0239\n",
      "Epoch 189/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0238\n",
      "Epoch 190/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0237\n",
      "Epoch 191/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0236\n",
      "Epoch 192/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0235\n",
      "Epoch 193/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0233\n",
      "Epoch 195/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0232\n",
      "Epoch 196/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0231\n",
      "Epoch 197/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0230\n",
      "Epoch 198/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0229\n",
      "Epoch 199/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0228\n",
      "Epoch 200/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0227\n",
      "Epoch 201/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0226\n",
      "Epoch 202/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0224\n",
      "Epoch 203/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0223\n",
      "Epoch 204/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0222\n",
      "Epoch 205/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0221\n",
      "Epoch 206/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0220\n",
      "Epoch 207/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0219\n",
      "Epoch 208/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0218\n",
      "Epoch 209/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0217\n",
      "Epoch 210/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0216\n",
      "Epoch 211/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0215\n",
      "Epoch 212/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0214\n",
      "Epoch 213/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0213\n",
      "Epoch 214/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0211\n",
      "Epoch 215/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0210\n",
      "Epoch 216/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0209\n",
      "Epoch 217/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0208\n",
      "Epoch 218/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0207\n",
      "Epoch 219/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0206\n",
      "Epoch 220/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0205\n",
      "Epoch 221/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0204\n",
      "Epoch 222/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0203\n",
      "Epoch 223/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0202\n",
      "Epoch 224/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0201\n",
      "Epoch 225/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0199\n",
      "Epoch 226/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0198\n",
      "Epoch 227/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0197\n",
      "Epoch 228/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0196\n",
      "Epoch 229/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0195\n",
      "Epoch 230/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0194\n",
      "Epoch 231/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0193\n",
      "Epoch 232/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0192\n",
      "Epoch 233/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0191\n",
      "Epoch 234/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0190\n",
      "Epoch 235/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0189\n",
      "Epoch 236/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0188\n",
      "Epoch 237/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0187\n",
      "Epoch 238/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0186\n",
      "Epoch 239/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0185\n",
      "Epoch 240/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0184\n",
      "Epoch 241/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0183\n",
      "Epoch 242/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0181\n",
      "Epoch 243/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0180\n",
      "Epoch 244/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0179\n",
      "Epoch 245/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0178\n",
      "Epoch 246/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0177\n",
      "Epoch 247/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0176\n",
      "Epoch 248/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0175\n",
      "Epoch 249/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0174\n",
      "Epoch 250/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0173\n",
      "Epoch 251/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0172\n",
      "Epoch 252/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0171\n",
      "Epoch 253/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0170\n",
      "Epoch 254/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0169\n",
      "Epoch 255/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0169\n",
      "Epoch 256/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0168\n",
      "Epoch 257/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0167\n",
      "Epoch 258/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0166\n",
      "Epoch 259/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0165\n",
      "Epoch 260/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0164\n",
      "Epoch 261/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0163\n",
      "Epoch 262/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0162\n",
      "Epoch 263/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0161\n",
      "Epoch 264/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0160\n",
      "Epoch 265/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0159\n",
      "Epoch 266/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0158\n",
      "Epoch 267/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0157\n",
      "Epoch 268/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0156\n",
      "Epoch 269/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0155\n",
      "Epoch 270/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0155\n",
      "Epoch 271/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0154\n",
      "Epoch 272/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0153\n",
      "Epoch 273/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0152\n",
      "Epoch 274/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0151\n",
      "Epoch 275/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0150\n",
      "Epoch 276/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0149\n",
      "Epoch 277/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0148\n",
      "Epoch 278/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0147\n",
      "Epoch 279/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0147\n",
      "Epoch 280/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0146\n",
      "Epoch 281/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0145\n",
      "Epoch 282/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0144\n",
      "Epoch 283/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0143\n",
      "Epoch 284/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0142\n",
      "Epoch 285/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0142\n",
      "Epoch 286/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0141\n",
      "Epoch 287/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0140\n",
      "Epoch 288/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0139\n",
      "Epoch 289/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0138\n",
      "Epoch 291/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0137\n",
      "Epoch 292/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0136\n",
      "Epoch 293/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0135\n",
      "Epoch 294/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0134\n",
      "Epoch 295/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0134\n",
      "Epoch 296/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0133\n",
      "Epoch 297/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0132\n",
      "Epoch 298/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0131\n",
      "Epoch 299/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0131\n",
      "Epoch 300/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0130\n",
      "Epoch 301/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0129\n",
      "Epoch 302/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0128\n",
      "Epoch 303/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0128\n",
      "Epoch 304/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0127\n",
      "Epoch 305/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0126\n",
      "Epoch 306/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0125\n",
      "Epoch 307/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0125\n",
      "Epoch 308/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0124\n",
      "Epoch 309/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0123\n",
      "Epoch 310/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0122\n",
      "Epoch 311/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0122\n",
      "Epoch 312/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0121\n",
      "Epoch 313/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0120\n",
      "Epoch 314/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0120\n",
      "Epoch 315/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0119\n",
      "Epoch 316/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0118\n",
      "Epoch 317/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0118\n",
      "Epoch 318/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0117\n",
      "Epoch 319/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0116\n",
      "Epoch 320/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0116\n",
      "Epoch 321/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0115\n",
      "Epoch 322/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0114\n",
      "Epoch 323/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0114\n",
      "Epoch 324/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0113\n",
      "Epoch 325/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0112\n",
      "Epoch 326/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0112\n",
      "Epoch 327/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0111\n",
      "Epoch 328/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0110\n",
      "Epoch 329/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0110\n",
      "Epoch 330/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0109\n",
      "Epoch 331/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0108\n",
      "Epoch 332/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0108\n",
      "Epoch 333/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0107\n",
      "Epoch 334/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0107\n",
      "Epoch 335/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0106\n",
      "Epoch 336/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0105\n",
      "Epoch 337/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0105\n",
      "Epoch 338/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0104\n",
      "Epoch 339/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0104\n",
      "Epoch 340/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0103\n",
      "Epoch 341/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0102\n",
      "Epoch 342/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0102\n",
      "Epoch 343/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0101\n",
      "Epoch 344/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0101\n",
      "Epoch 345/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0100\n",
      "Epoch 346/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0100\n",
      "Epoch 347/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0099\n",
      "Epoch 348/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0099\n",
      "Epoch 349/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0098\n",
      "Epoch 350/800\n",
      "20/20 [==============================] - 0s 102us/sample - loss: 0.0097\n",
      "Epoch 351/800\n",
      "20/20 [==============================] - 0s 149us/sample - loss: 0.0097\n",
      "Epoch 352/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0096\n",
      "Epoch 353/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0096\n",
      "Epoch 354/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0095\n",
      "Epoch 355/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0095\n",
      "Epoch 356/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0094\n",
      "Epoch 357/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0094\n",
      "Epoch 358/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0093\n",
      "Epoch 359/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0093\n",
      "Epoch 360/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0092\n",
      "Epoch 361/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0092\n",
      "Epoch 362/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0091\n",
      "Epoch 363/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0091\n",
      "Epoch 364/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0090\n",
      "Epoch 365/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0090\n",
      "Epoch 366/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0089\n",
      "Epoch 367/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0089\n",
      "Epoch 368/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0088\n",
      "Epoch 369/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0088\n",
      "Epoch 370/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0087\n",
      "Epoch 371/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0087\n",
      "Epoch 372/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0086\n",
      "Epoch 373/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0086\n",
      "Epoch 374/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0085\n",
      "Epoch 375/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0085\n",
      "Epoch 376/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0084\n",
      "Epoch 377/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0084\n",
      "Epoch 378/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0083\n",
      "Epoch 379/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0083\n",
      "Epoch 380/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0083\n",
      "Epoch 381/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0082\n",
      "Epoch 382/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0082\n",
      "Epoch 383/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0081\n",
      "Epoch 384/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0081\n",
      "Epoch 385/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0080\n",
      "Epoch 387/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0080\n",
      "Epoch 388/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0079\n",
      "Epoch 389/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0079\n",
      "Epoch 390/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0078\n",
      "Epoch 391/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0078\n",
      "Epoch 392/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0077\n",
      "Epoch 393/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0077\n",
      "Epoch 394/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0077\n",
      "Epoch 395/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0076\n",
      "Epoch 396/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0076\n",
      "Epoch 397/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0076\n",
      "Epoch 398/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0075\n",
      "Epoch 399/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0075\n",
      "Epoch 400/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0074\n",
      "Epoch 401/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0074\n",
      "Epoch 402/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0074\n",
      "Epoch 403/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0073\n",
      "Epoch 404/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0073\n",
      "Epoch 405/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0073\n",
      "Epoch 406/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0072\n",
      "Epoch 407/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0072\n",
      "Epoch 408/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0071\n",
      "Epoch 409/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0071\n",
      "Epoch 410/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0071\n",
      "Epoch 411/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0070\n",
      "Epoch 412/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0070\n",
      "Epoch 413/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0070\n",
      "Epoch 414/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0069\n",
      "Epoch 415/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0069\n",
      "Epoch 416/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0069\n",
      "Epoch 417/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0068\n",
      "Epoch 418/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0068\n",
      "Epoch 419/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0068\n",
      "Epoch 420/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0067\n",
      "Epoch 421/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0067\n",
      "Epoch 422/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0067\n",
      "Epoch 423/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0066\n",
      "Epoch 424/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0066\n",
      "Epoch 425/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0066\n",
      "Epoch 426/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0066\n",
      "Epoch 427/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0065\n",
      "Epoch 428/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0065\n",
      "Epoch 429/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0065\n",
      "Epoch 430/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0064\n",
      "Epoch 431/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0064\n",
      "Epoch 432/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0064\n",
      "Epoch 433/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0063\n",
      "Epoch 434/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0063\n",
      "Epoch 435/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0063\n",
      "Epoch 436/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0063\n",
      "Epoch 437/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0062\n",
      "Epoch 438/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0062\n",
      "Epoch 439/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0062\n",
      "Epoch 440/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0062\n",
      "Epoch 441/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0061\n",
      "Epoch 442/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0061\n",
      "Epoch 443/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0061\n",
      "Epoch 444/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0060\n",
      "Epoch 445/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0060\n",
      "Epoch 446/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0060\n",
      "Epoch 447/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0060\n",
      "Epoch 448/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0059\n",
      "Epoch 449/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0059\n",
      "Epoch 450/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0059\n",
      "Epoch 451/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0059\n",
      "Epoch 452/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0059\n",
      "Epoch 453/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0058\n",
      "Epoch 454/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0058\n",
      "Epoch 455/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0058\n",
      "Epoch 456/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0058\n",
      "Epoch 457/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0057\n",
      "Epoch 458/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0057\n",
      "Epoch 459/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0057\n",
      "Epoch 460/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0057\n",
      "Epoch 461/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0056\n",
      "Epoch 462/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0056\n",
      "Epoch 463/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0056\n",
      "Epoch 464/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0056\n",
      "Epoch 465/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0056\n",
      "Epoch 466/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0055\n",
      "Epoch 467/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0055\n",
      "Epoch 468/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0055\n",
      "Epoch 469/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0055\n",
      "Epoch 470/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0055\n",
      "Epoch 471/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0054\n",
      "Epoch 472/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0054\n",
      "Epoch 473/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0054\n",
      "Epoch 474/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0054\n",
      "Epoch 475/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0054\n",
      "Epoch 476/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0053\n",
      "Epoch 477/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0053\n",
      "Epoch 478/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0053\n",
      "Epoch 479/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0053\n",
      "Epoch 480/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0053\n",
      "Epoch 481/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0052\n",
      "Epoch 483/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0052\n",
      "Epoch 484/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0052\n",
      "Epoch 485/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0052\n",
      "Epoch 486/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0052\n",
      "Epoch 487/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0051\n",
      "Epoch 488/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0051\n",
      "Epoch 489/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0051\n",
      "Epoch 490/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0051\n",
      "Epoch 491/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0051\n",
      "Epoch 492/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0050\n",
      "Epoch 493/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0050\n",
      "Epoch 494/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0050\n",
      "Epoch 495/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0050\n",
      "Epoch 496/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0050\n",
      "Epoch 497/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0050\n",
      "Epoch 498/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0049\n",
      "Epoch 499/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0049\n",
      "Epoch 500/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0049\n",
      "Epoch 501/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0049\n",
      "Epoch 502/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0049\n",
      "Epoch 503/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0049\n",
      "Epoch 504/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0049\n",
      "Epoch 505/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0048\n",
      "Epoch 506/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0048\n",
      "Epoch 507/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0048\n",
      "Epoch 508/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0048\n",
      "Epoch 509/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0048\n",
      "Epoch 510/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0048\n",
      "Epoch 511/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0048\n",
      "Epoch 512/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0047\n",
      "Epoch 513/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0047\n",
      "Epoch 514/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0047\n",
      "Epoch 515/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0047\n",
      "Epoch 516/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0047\n",
      "Epoch 517/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0047\n",
      "Epoch 518/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0047\n",
      "Epoch 519/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0046\n",
      "Epoch 520/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0046\n",
      "Epoch 521/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0046\n",
      "Epoch 522/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0046\n",
      "Epoch 523/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0046\n",
      "Epoch 524/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0046\n",
      "Epoch 525/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0046\n",
      "Epoch 526/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0046\n",
      "Epoch 527/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0045\n",
      "Epoch 528/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0045\n",
      "Epoch 529/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0045\n",
      "Epoch 530/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0045\n",
      "Epoch 531/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0045\n",
      "Epoch 532/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0045\n",
      "Epoch 533/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0045\n",
      "Epoch 534/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0045\n",
      "Epoch 535/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0045\n",
      "Epoch 536/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0045\n",
      "Epoch 537/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0044\n",
      "Epoch 538/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0044\n",
      "Epoch 539/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0044\n",
      "Epoch 540/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0044\n",
      "Epoch 541/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0044\n",
      "Epoch 542/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0044\n",
      "Epoch 543/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0044\n",
      "Epoch 544/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0044\n",
      "Epoch 545/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0044\n",
      "Epoch 546/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0044\n",
      "Epoch 547/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0043\n",
      "Epoch 548/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 549/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0043\n",
      "Epoch 550/800\n",
      "20/20 [==============================] - 0s 149us/sample - loss: 0.0043\n",
      "Epoch 551/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0043\n",
      "Epoch 552/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 553/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 554/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 555/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0043\n",
      "Epoch 556/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0043\n",
      "Epoch 557/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 558/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0043\n",
      "Epoch 559/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0043\n",
      "Epoch 560/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0043\n",
      "Epoch 561/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0042\n",
      "Epoch 562/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 563/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 564/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 565/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0042\n",
      "Epoch 566/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 567/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0042\n",
      "Epoch 568/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0042\n",
      "Epoch 569/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0042\n",
      "Epoch 570/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 571/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0042\n",
      "Epoch 572/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0042\n",
      "Epoch 573/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 574/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 575/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 576/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0042\n",
      "Epoch 577/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0042\n",
      "Epoch 579/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 580/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 581/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 582/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 583/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0041\n",
      "Epoch 584/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 585/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 586/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0041\n",
      "Epoch 587/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 588/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 589/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 590/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 591/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 592/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0041\n",
      "Epoch 593/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0041\n",
      "Epoch 594/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 595/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0041\n",
      "Epoch 596/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 597/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 598/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 599/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 600/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 601/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 602/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 603/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 604/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0041\n",
      "Epoch 605/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 606/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0041\n",
      "Epoch 607/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 608/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 609/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 610/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0040\n",
      "Epoch 611/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 612/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 613/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 614/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 615/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 616/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 617/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 618/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 619/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 620/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 621/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 622/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 623/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 624/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0040\n",
      "Epoch 625/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 626/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 627/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0040\n",
      "Epoch 628/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 629/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 630/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 631/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 632/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 633/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0040\n",
      "Epoch 634/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 635/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 636/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 637/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 638/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 639/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 640/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 641/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 642/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0040\n",
      "Epoch 643/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 644/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 645/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 646/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 647/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 648/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0040\n",
      "Epoch 649/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 650/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 651/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 652/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0040\n",
      "Epoch 653/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 654/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 655/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0040\n",
      "Epoch 656/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 657/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 658/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 659/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 660/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 661/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 662/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 663/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 664/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 665/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 666/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0040\n",
      "Epoch 667/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0040\n",
      "Epoch 668/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0040\n",
      "Epoch 669/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 670/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 671/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0040\n",
      "Epoch 672/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0039\n",
      "Epoch 673/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 675/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 676/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 677/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0039\n",
      "Epoch 678/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 679/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 680/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 681/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 682/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 683/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 684/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 685/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0039\n",
      "Epoch 686/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 687/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0039\n",
      "Epoch 688/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 689/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 690/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0039\n",
      "Epoch 691/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0039\n",
      "Epoch 692/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 693/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 694/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 695/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 696/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 697/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 698/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 699/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 700/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 701/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 702/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0039\n",
      "Epoch 703/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0039\n",
      "Epoch 704/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0039\n",
      "Epoch 705/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 706/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 707/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 708/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 709/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 710/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 711/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0039\n",
      "Epoch 712/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 713/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 714/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 715/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 716/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 717/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 718/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 719/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 720/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 721/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 722/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 723/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 724/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 725/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 726/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0039\n",
      "Epoch 727/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 728/800\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.0039\n",
      "Epoch 729/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0039\n",
      "Epoch 730/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 731/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 732/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 733/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 734/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 735/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 736/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 737/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 738/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 739/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 740/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 741/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 742/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 743/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 744/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 745/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 746/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 747/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 748/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0039\n",
      "Epoch 749/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 750/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 751/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 752/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 753/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 754/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 755/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 756/800\n",
      "20/20 [==============================] - 0s 48us/sample - loss: 0.0039\n",
      "Epoch 757/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 758/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 759/800\n",
      "20/20 [==============================] - 0s 151us/sample - loss: 0.0039\n",
      "Epoch 760/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0039\n",
      "Epoch 761/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 762/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 763/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 764/800\n",
      "20/20 [==============================] - 0s 148us/sample - loss: 0.0039\n",
      "Epoch 765/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 766/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 767/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 768/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 769/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 771/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 772/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 773/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 774/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 775/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 776/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 777/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 778/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 779/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 780/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 781/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 782/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 783/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 784/800\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0039\n",
      "Epoch 785/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 786/800\n",
      "20/20 [==============================] - 0s 50us/sample - loss: 0.0039\n",
      "Epoch 787/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 788/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 789/800\n",
      "20/20 [==============================] - 0s 49us/sample - loss: 0.0039\n",
      "Epoch 790/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 791/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 792/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 793/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 794/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 795/800\n",
      "20/20 [==============================] - 0s 101us/sample - loss: 0.0039\n",
      "Epoch 796/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 797/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 798/800\n",
      "20/20 [==============================] - 0s 98us/sample - loss: 0.0039\n",
      "Epoch 799/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n",
      "Epoch 800/800\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_layers = 5\n",
    "\n",
    "\n",
    "def loss(y, y_pred):\n",
    "    return tf.reduce_mean((y_pred-y)**2)\n",
    "\n",
    "\n",
    "def maxis(y):\n",
    "    return tf.reduce_max(y)\n",
    "  \n",
    "    \n",
    "def distribution_model(num_layers):\n",
    "    inputs_ = layers.Input((1,))\n",
    "    sp = []\n",
    "    for i in range(5):\n",
    "        sp.append(DestributionLayer((np.random.rand(1)*2-1)*2, 0.5)(inputs_))\n",
    "    predictions = sum(sp)\n",
    "\n",
    "    model_ = tf.keras.Model(\n",
    "            inputs=inputs_, \n",
    "            outputs=predictions)\n",
    "\n",
    "    model_.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "                  loss=loss)\n",
    "    \n",
    "    return model_\n",
    "\n",
    "\n",
    "model = distribution_model(num_layers)\n",
    "model.fit(x, y, batch_size=len(x), epochs=800)\n",
    "plt.plot(x, model(x))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a long-run calculation, skip it if you have weather_train_ditributions.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1566\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.5082\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3528\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.6067\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4706\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.6634\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 44ms/sample - loss: 0.0931\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.5882\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1222\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.2773\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 45ms/sample - loss: 0.3191\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 27ms/sample - loss: 0.5425\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.2981\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.6120\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.1742\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 45ms/sample - loss: 1.1111\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3066\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.7345\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.2123\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 43ms/sample - loss: 0.5933\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.2809\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.3731\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.3348\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.4669\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 45ms/sample - loss: 0.1882\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.4947\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3750\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 1.3630\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.6255\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 45ms/sample - loss: 0.6492\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.2693\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.5852\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.1926\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1598\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 46ms/sample - loss: 0.3477\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4308\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.1848\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.6687\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.4076\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.9174\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.4588\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.6689\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.2127\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1678\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 46ms/sample - loss: 0.5041\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 1.1664\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 27ms/sample - loss: 0.5395\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.4871\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3734\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 47ms/sample - loss: 0.8287\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.4672\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 1.2817\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.3292\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4336\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 48ms/sample - loss: 0.3733\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.4935\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4043\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 3.0334\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4305\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.5306\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 48ms/sample - loss: 0.3532\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.5440\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.1494\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.8087\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3975\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.6325\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1951\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.1707\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.3361\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.7684\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.4502\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.6757\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.2728\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.6662\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.1045\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 2.1552\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.3374\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 24ms/sample - loss: 0.4213\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 50ms/sample - loss: 0.2687\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.5472\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.1691\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.7489\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.3013\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4024\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 51ms/sample - loss: 0.2016\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.7694\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.3454\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 1.1768\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.3716\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 25ms/sample - loss: 0.5495\n",
      "Train on 20 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 50ms/sample - loss: 0.2756\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.5058\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.3988\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 1.3026\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 1s 26ms/sample - loss: 0.5812\n",
      "Train on 20 samples\n",
      "20/20 [==============================] - 0s 25ms/sample - loss: 0.4827\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we have a distribution layer and model with several of them\n",
    "# so, we can simulate any distribution for any column for any site_id\n",
    "\n",
    "columns_list = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "weather_distrib = pd.DataFrame(columns = ['site_id']+[i + '_' + j for i in columns_list \n",
    "                                    for j in list(itertools.chain(*[['mu' + str(i), 'st' + str(i)]\n",
    "                                                                for i in range(num_layers)]))]).set_index('site_id')\n",
    "for testing_site_index in weather_train['site_id'].unique():  \n",
    "    \n",
    "    testing_site_id = weather_train[weather_train['site_id'] == testing_site_index].drop('site_id', axis=1)\n",
    "    testing_site_id = testing_site_id.drop('timestamp', axis=1)\n",
    "    testing_site_id = testing_site_id.drop('precip_depth_1_hr', axis=1)\n",
    "    \n",
    "    for i in testing_site_id.columns:\n",
    "        try:\n",
    "            testing_site_id = fillna_by_time(testing_site_id, i)\n",
    "        except AssertionError:\n",
    "            testing_site_id[i].fillna(0, inplace=True)\n",
    "            testing_site_id = fillna_by_time(testing_site_id, i)\n",
    "    \n",
    "    data_per_site_id = []\n",
    "    for i in testing_site_id.columns:\n",
    "        temp = []\n",
    "        model = distribution_model(num_layers)\n",
    "        x, y = get_in_columns(i, testing_site_id)\n",
    "        model.fit(x, y, batch_size=len(x), epochs=800)\n",
    "\n",
    "        for j in model.weights:\n",
    "            temp.append(j.numpy()[0])\n",
    "\n",
    "        temp = [[temp[i*2], temp[i*2+1]] for i in range(num_layers)]\n",
    "        temp.sort()\n",
    "        data_per_site_id.append(list(itertools.chain(*temp)))\n",
    "\n",
    "    weather_distrib.loc[testing_site_index] = [data_per_site_id[i][j] \n",
    "                                         for i in range(len(testing_site_id.columns)) \n",
    "                                         for j in range(num_layers*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_distrib.to_csv('.\\data\\\\weather_train_ditributions.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model (naive approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_distrib = pd.read_csv('.\\data\\\\weather_train_ditributions.csv').set_index('site_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if you want to apply weather_distrib parametres\n",
    "test_train = electricity.set_index('site_id').join(\n",
    "    weather_distrib, on='site_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if you don't want to apply weather_distrib parametres\n",
    "test_train = electricity.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_oh = ['primary_use', 'year_built']\n",
    "for col in columns_to_oh:\n",
    "    one_hot = pd.get_dummies(test_train[col])\n",
    "    one_hot.columns = [f'{col}_one_hot_{str(val)}' for val in one_hot.columns]\n",
    "    test_train = pd.concat([test_train, one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>primary_use_one_hot_Education</th>\n",
       "      <th>primary_use_one_hot_Entertainment/public assembly</th>\n",
       "      <th>primary_use_one_hot_Food sales and service</th>\n",
       "      <th>primary_use_one_hot_Healthcare</th>\n",
       "      <th>primary_use_one_hot_Lodging/residential</th>\n",
       "      <th>primary_use_one_hot_Manufacturing/industrial</th>\n",
       "      <th>primary_use_one_hot_Office</th>\n",
       "      <th>...</th>\n",
       "      <th>year_built_one_hot_2008.0</th>\n",
       "      <th>year_built_one_hot_2009.0</th>\n",
       "      <th>year_built_one_hot_2010.0</th>\n",
       "      <th>year_built_one_hot_2011.0</th>\n",
       "      <th>year_built_one_hot_2012.0</th>\n",
       "      <th>year_built_one_hot_2013.0</th>\n",
       "      <th>year_built_one_hot_2014.0</th>\n",
       "      <th>year_built_one_hot_2015.0</th>\n",
       "      <th>year_built_one_hot_2016.0</th>\n",
       "      <th>year_built_one_hot_2017.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5376</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>116607</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  square_feet  floor_count  primary_use_one_hot_Education  \\\n",
       "0        0         7432          3.0                              1   \n",
       "1        0         2720          3.0                              1   \n",
       "2        0         5376          3.0                              1   \n",
       "3        0        23685          3.0                              1   \n",
       "4        0       116607          3.0                              1   \n",
       "\n",
       "   primary_use_one_hot_Entertainment/public assembly  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "   primary_use_one_hot_Food sales and service  primary_use_one_hot_Healthcare  \\\n",
       "0                                           0                               0   \n",
       "1                                           0                               0   \n",
       "2                                           0                               0   \n",
       "3                                           0                               0   \n",
       "4                                           0                               0   \n",
       "\n",
       "   primary_use_one_hot_Lodging/residential  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   primary_use_one_hot_Manufacturing/industrial  primary_use_one_hot_Office  \\\n",
       "0                                             0                           0   \n",
       "1                                             0                           0   \n",
       "2                                             0                           0   \n",
       "3                                             0                           0   \n",
       "4                                             0                           0   \n",
       "\n",
       "   ...  year_built_one_hot_2008.0  year_built_one_hot_2009.0  \\\n",
       "0  ...                          1                          0   \n",
       "1  ...                          0                          0   \n",
       "2  ...                          0                          0   \n",
       "3  ...                          0                          0   \n",
       "4  ...                          0                          0   \n",
       "\n",
       "   year_built_one_hot_2010.0  year_built_one_hot_2011.0  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   year_built_one_hot_2012.0  year_built_one_hot_2013.0  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   year_built_one_hot_2014.0  year_built_one_hot_2015.0  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   year_built_one_hot_2016.0  year_built_one_hot_2017.0  \n",
       "0                          0                          0  \n",
       "1                          0                          0  \n",
       "2                          0                          0  \n",
       "3                          0                          0  \n",
       "4                          0                          0  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train = test_train.drop(columns_to_oh, axis=1).drop('timestamp', axis=1).drop('meter_reading', axis=1)\n",
    "test_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "90000/90000 [==============================] - 1s 7us/sample - loss: 127.3741 - val_loss: 128.4343\n",
      "Epoch 2/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 127.2305 - val_loss: 128.2914\n",
      "Epoch 3/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 127.0877 - val_loss: 128.1493\n",
      "Epoch 4/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.9466 - val_loss: 128.0095\n",
      "Epoch 5/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.8073 - val_loss: 127.8707\n",
      "Epoch 6/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.6690 - val_loss: 127.7330\n",
      "Epoch 7/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.5314 - val_loss: 127.5960\n",
      "Epoch 8/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.3957 - val_loss: 127.4619\n",
      "Epoch 9/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.2622 - val_loss: 127.3285\n",
      "Epoch 10/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 126.1296 - val_loss: 127.1961\n",
      "Epoch 11/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.9984 - val_loss: 127.0648\n",
      "Epoch 12/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.8683 - val_loss: 126.9342\n",
      "Epoch 13/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.7393 - val_loss: 126.8047\n",
      "Epoch 14/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.6111 - val_loss: 126.6759\n",
      "Epoch 15/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.4838 - val_loss: 126.5481\n",
      "Epoch 16/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.3577 - val_loss: 126.4215\n",
      "Epoch 17/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.2325 - val_loss: 126.2960\n",
      "Epoch 18/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 125.1083 - val_loss: 126.1711\n",
      "Epoch 19/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.9848 - val_loss: 126.0475\n",
      "Epoch 20/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.8627 - val_loss: 125.9256\n",
      "Epoch 21/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.7425 - val_loss: 125.8051\n",
      "Epoch 22/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.6235 - val_loss: 125.6856\n",
      "Epoch 23/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.5055 - val_loss: 125.5672\n",
      "Epoch 24/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.3887 - val_loss: 125.4502\n",
      "Epoch 25/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.2733 - val_loss: 125.3344\n",
      "Epoch 26/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.1583 - val_loss: 125.2187\n",
      "Epoch 27/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 124.0438 - val_loss: 125.1037\n",
      "Epoch 28/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.9304 - val_loss: 124.9898\n",
      "Epoch 29/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.8177 - val_loss: 124.8765\n",
      "Epoch 30/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.7057 - val_loss: 124.7643\n",
      "Epoch 31/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.5949 - val_loss: 124.6532\n",
      "Epoch 32/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.4852 - val_loss: 124.5435\n",
      "Epoch 33/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.3764 - val_loss: 124.4341\n",
      "Epoch 34/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.2680 - val_loss: 124.3250\n",
      "Epoch 35/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.1599 - val_loss: 124.2160\n",
      "Epoch 36/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 123.0523 - val_loss: 124.1078\n",
      "Epoch 37/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.9454 - val_loss: 124.0002\n",
      "Epoch 38/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.8388 - val_loss: 123.8932\n",
      "Epoch 39/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.7326 - val_loss: 123.7865\n",
      "Epoch 40/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.6274 - val_loss: 123.6810\n",
      "Epoch 41/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.5230 - val_loss: 123.5757\n",
      "Epoch 42/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.4192 - val_loss: 123.4716\n",
      "Epoch 43/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.3165 - val_loss: 123.3681\n",
      "Epoch 44/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.2148 - val_loss: 123.2656\n",
      "Epoch 45/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.1139 - val_loss: 123.1641\n",
      "Epoch 46/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 122.0137 - val_loss: 123.0634\n",
      "Epoch 47/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.9138 - val_loss: 122.9630\n",
      "Epoch 48/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.8147 - val_loss: 122.8634\n",
      "Epoch 49/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.7162 - val_loss: 122.7642\n",
      "Epoch 50/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.6182 - val_loss: 122.6658\n",
      "Epoch 51/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.5208 - val_loss: 122.5678\n",
      "Epoch 52/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.4238 - val_loss: 122.4704\n",
      "Epoch 53/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.3271 - val_loss: 122.3734\n",
      "Epoch 54/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.2308 - val_loss: 122.2772\n",
      "Epoch 55/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.1351 - val_loss: 122.1812\n",
      "Epoch 56/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 121.0397 - val_loss: 122.0856\n",
      "Epoch 57/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.9448 - val_loss: 121.9904\n",
      "Epoch 58/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.8503 - val_loss: 121.8956\n",
      "Epoch 59/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.7563 - val_loss: 121.8017\n",
      "Epoch 60/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.6631 - val_loss: 121.7085\n",
      "Epoch 61/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.5706 - val_loss: 121.6155\n",
      "Epoch 62/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.4784 - val_loss: 121.5229\n",
      "Epoch 63/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.3866 - val_loss: 121.4306\n",
      "Epoch 64/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.2952 - val_loss: 121.3387\n",
      "Epoch 65/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.2042 - val_loss: 121.2471\n",
      "Epoch 66/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.1140 - val_loss: 121.1561\n",
      "Epoch 67/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 120.0244 - val_loss: 121.0657\n",
      "Epoch 68/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.9356 - val_loss: 120.9758\n",
      "Epoch 69/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.8475 - val_loss: 120.8865\n",
      "Epoch 70/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.7601 - val_loss: 120.7975\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.6731 - val_loss: 120.7095\n",
      "Epoch 72/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.5869 - val_loss: 120.6220\n",
      "Epoch 73/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.5013 - val_loss: 120.5355\n",
      "Epoch 74/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.4167 - val_loss: 120.4500\n",
      "Epoch 75/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.3332 - val_loss: 120.3658\n",
      "Epoch 76/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.2503 - val_loss: 120.2826\n",
      "Epoch 77/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.1682 - val_loss: 120.2008\n",
      "Epoch 78/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.0873 - val_loss: 120.1205\n",
      "Epoch 79/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 119.0072 - val_loss: 120.0412\n",
      "Epoch 80/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.9281 - val_loss: 119.9629\n",
      "Epoch 81/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.8498 - val_loss: 119.8852\n",
      "Epoch 82/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.7719 - val_loss: 119.8076\n",
      "Epoch 83/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.6946 - val_loss: 119.7308\n",
      "Epoch 84/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.6183 - val_loss: 119.6546\n",
      "Epoch 85/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.5424 - val_loss: 119.5788\n",
      "Epoch 86/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.4670 - val_loss: 119.5036\n",
      "Epoch 87/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.3923 - val_loss: 119.4291\n",
      "Epoch 88/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.3179 - val_loss: 119.3546\n",
      "Epoch 89/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.2441 - val_loss: 119.2807\n",
      "Epoch 90/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.1714 - val_loss: 119.2079\n",
      "Epoch 91/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.0993 - val_loss: 119.1353\n",
      "Epoch 92/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 118.0277 - val_loss: 119.0629\n",
      "Epoch 93/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.9564 - val_loss: 118.9911\n",
      "Epoch 94/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.8853 - val_loss: 118.9191\n",
      "Epoch 95/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.8148 - val_loss: 118.8477\n",
      "Epoch 96/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.7454 - val_loss: 118.7771\n",
      "Epoch 97/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.6764 - val_loss: 118.7064\n",
      "Epoch 98/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.6078 - val_loss: 118.6364\n",
      "Epoch 99/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.5395 - val_loss: 118.5669\n",
      "Epoch 100/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.4720 - val_loss: 118.4979\n",
      "Epoch 101/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.4051 - val_loss: 118.4300\n",
      "Epoch 102/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.3391 - val_loss: 118.3627\n",
      "Epoch 103/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.2736 - val_loss: 118.2955\n",
      "Epoch 104/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.2087 - val_loss: 118.2290\n",
      "Epoch 105/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.1443 - val_loss: 118.1627\n",
      "Epoch 106/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.0803 - val_loss: 118.0966\n",
      "Epoch 107/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 117.0169 - val_loss: 118.0317\n",
      "Epoch 108/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.9548 - val_loss: 117.9681\n",
      "Epoch 109/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 116.8932 - val_loss: 117.9050\n",
      "Epoch 110/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 116.8322 - val_loss: 117.8425\n",
      "Epoch 111/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.7718 - val_loss: 117.7807\n",
      "Epoch 112/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.7119 - val_loss: 117.7196\n",
      "Epoch 113/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 116.6527 - val_loss: 117.6592\n",
      "Epoch 114/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.5945 - val_loss: 117.5992\n",
      "Epoch 115/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.5368 - val_loss: 117.5400\n",
      "Epoch 116/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.4793 - val_loss: 117.4810\n",
      "Epoch 117/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.4222 - val_loss: 117.4222\n",
      "Epoch 118/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.3657 - val_loss: 117.3640\n",
      "Epoch 119/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.3097 - val_loss: 117.3068\n",
      "Epoch 120/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.2557 - val_loss: 117.2511\n",
      "Epoch 121/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.2026 - val_loss: 117.1957\n",
      "Epoch 122/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.1496 - val_loss: 117.1404\n",
      "Epoch 123/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.0970 - val_loss: 117.0850\n",
      "Epoch 124/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 116.0446 - val_loss: 117.0303\n",
      "Epoch 125/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.9928 - val_loss: 116.9767\n",
      "Epoch 126/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.9426 - val_loss: 116.9239\n",
      "Epoch 127/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.8929 - val_loss: 116.8714\n",
      "Epoch 128/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.8436 - val_loss: 116.8192\n",
      "Epoch 129/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.7946 - val_loss: 116.7672\n",
      "Epoch 130/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.7466 - val_loss: 116.7162\n",
      "Epoch 131/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.6994 - val_loss: 116.6653\n",
      "Epoch 132/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.6527 - val_loss: 116.6149\n",
      "Epoch 133/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.6064 - val_loss: 116.5646\n",
      "Epoch 134/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.5604 - val_loss: 116.5145\n",
      "Epoch 135/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.5147 - val_loss: 116.4648\n",
      "Epoch 136/1000\n",
      "90000/90000 [==============================] - ETA: 0s - loss: 115.545 - 1s 6us/sample - loss: 115.4694 - val_loss: 116.4152\n",
      "Epoch 137/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.4245 - val_loss: 116.3662\n",
      "Epoch 138/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.3802 - val_loss: 116.3178\n",
      "Epoch 139/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.3365 - val_loss: 116.2697\n",
      "Epoch 140/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.2931 - val_loss: 116.2218\n",
      "Epoch 141/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.2501 - val_loss: 116.1744\n",
      "Epoch 142/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.2075 - val_loss: 116.1271\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.1653 - val_loss: 116.0804\n",
      "Epoch 144/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.1242 - val_loss: 116.0351\n",
      "Epoch 145/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.0843 - val_loss: 115.9902\n",
      "Epoch 146/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.0449 - val_loss: 115.9460\n",
      "Epoch 147/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 115.0061 - val_loss: 115.9019\n",
      "Epoch 148/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.9674 - val_loss: 115.8584\n",
      "Epoch 149/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.9291 - val_loss: 115.8147\n",
      "Epoch 150/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.8914 - val_loss: 115.7735\n",
      "Epoch 151/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.8557 - val_loss: 115.7331\n",
      "Epoch 152/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.8205 - val_loss: 115.6931\n",
      "Epoch 153/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.7857 - val_loss: 115.6536\n",
      "Epoch 154/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.7512 - val_loss: 115.6142\n",
      "Epoch 155/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.7169 - val_loss: 115.5750\n",
      "Epoch 156/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.6829 - val_loss: 115.5364\n",
      "Epoch 157/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.6498 - val_loss: 115.4981\n",
      "Epoch 158/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.6170 - val_loss: 115.4606\n",
      "Epoch 159/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.5843 - val_loss: 115.4231\n",
      "Epoch 160/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.5518 - val_loss: 115.3858\n",
      "Epoch 161/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.5197 - val_loss: 115.3490\n",
      "Epoch 162/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.4880 - val_loss: 115.3127\n",
      "Epoch 163/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.4570 - val_loss: 115.2772\n",
      "Epoch 164/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.4265 - val_loss: 115.2420\n",
      "Epoch 165/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.3962 - val_loss: 115.2071\n",
      "Epoch 166/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.3661 - val_loss: 115.1725\n",
      "Epoch 167/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.3364 - val_loss: 115.1381\n",
      "Epoch 168/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.3071 - val_loss: 115.1040\n",
      "Epoch 169/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.2783 - val_loss: 115.0710\n",
      "Epoch 170/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.2502 - val_loss: 115.0378\n",
      "Epoch 171/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.2223 - val_loss: 115.0050\n",
      "Epoch 172/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.1945 - val_loss: 114.9725\n",
      "Epoch 173/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.1669 - val_loss: 114.9399\n",
      "Epoch 174/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.1395 - val_loss: 114.9079\n",
      "Epoch 175/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.1125 - val_loss: 114.8763\n",
      "Epoch 176/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.0864 - val_loss: 114.8456\n",
      "Epoch 177/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.0609 - val_loss: 114.8156\n",
      "Epoch 178/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.0357 - val_loss: 114.7857\n",
      "Epoch 179/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 114.0110 - val_loss: 114.7563\n",
      "Epoch 180/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.9864 - val_loss: 114.7270\n",
      "Epoch 181/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.9622 - val_loss: 114.6982\n",
      "Epoch 182/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.9387 - val_loss: 114.6706\n",
      "Epoch 183/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.9158 - val_loss: 114.6427\n",
      "Epoch 184/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.8931 - val_loss: 114.6152\n",
      "Epoch 185/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.8705 - val_loss: 114.5875\n",
      "Epoch 186/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.8480 - val_loss: 114.5602\n",
      "Epoch 187/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.8258 - val_loss: 114.5330\n",
      "Epoch 188/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.8042 - val_loss: 114.5069\n",
      "Epoch 189/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.7833 - val_loss: 114.4811\n",
      "Epoch 190/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.7626 - val_loss: 114.4554\n",
      "Epoch 191/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.7420 - val_loss: 114.4298\n",
      "Epoch 192/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.7216 - val_loss: 114.4044\n",
      "Epoch 193/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.7015 - val_loss: 114.3794\n",
      "Epoch 194/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.6815 - val_loss: 114.3546\n",
      "Epoch 195/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.6625 - val_loss: 114.3309\n",
      "Epoch 196/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.6438 - val_loss: 114.3074\n",
      "Epoch 197/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.6252 - val_loss: 114.2841\n",
      "Epoch 198/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.6069 - val_loss: 114.2612\n",
      "Epoch 199/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5889 - val_loss: 114.2387\n",
      "Epoch 200/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5713 - val_loss: 114.2167\n",
      "Epoch 201/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5543 - val_loss: 114.1955\n",
      "Epoch 202/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5380 - val_loss: 114.1750\n",
      "Epoch 203/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5219 - val_loss: 114.1545\n",
      "Epoch 204/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.5061 - val_loss: 114.1343\n",
      "Epoch 205/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4904 - val_loss: 114.1143\n",
      "Epoch 206/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4749 - val_loss: 114.0942\n",
      "Epoch 207/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4597 - val_loss: 114.0748\n",
      "Epoch 208/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4449 - val_loss: 114.0557\n",
      "Epoch 209/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4304 - val_loss: 114.0369\n",
      "Epoch 210/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4161 - val_loss: 114.0182\n",
      "Epoch 211/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.4021 - val_loss: 113.9997\n",
      "Epoch 212/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3882 - val_loss: 113.9815\n",
      "Epoch 213/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3747 - val_loss: 113.9635\n",
      "Epoch 214/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3614 - val_loss: 113.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3487 - val_loss: 113.9292\n",
      "Epoch 216/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3364 - val_loss: 113.9124\n",
      "Epoch 217/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3243 - val_loss: 113.8961\n",
      "Epoch 218/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3125 - val_loss: 113.8799\n",
      "Epoch 219/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.3009 - val_loss: 113.8639\n",
      "Epoch 220/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2895 - val_loss: 113.8482\n",
      "Epoch 221/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2784 - val_loss: 113.8329\n",
      "Epoch 222/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2678 - val_loss: 113.8183\n",
      "Epoch 223/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2575 - val_loss: 113.8038\n",
      "Epoch 224/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2475 - val_loss: 113.7896\n",
      "Epoch 225/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2376 - val_loss: 113.7756\n",
      "Epoch 226/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2278 - val_loss: 113.7617\n",
      "Epoch 227/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2183 - val_loss: 113.7479\n",
      "Epoch 228/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.2090 - val_loss: 113.7342\n",
      "Epoch 229/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1999 - val_loss: 113.7214\n",
      "Epoch 230/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1914 - val_loss: 113.7090\n",
      "Epoch 231/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1830 - val_loss: 113.6967\n",
      "Epoch 232/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1749 - val_loss: 113.6849\n",
      "Epoch 233/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1671 - val_loss: 113.6740\n",
      "Epoch 234/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.1596 - val_loss: 113.6630\n",
      "Epoch 235/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1523 - val_loss: 113.6524\n",
      "Epoch 236/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1452 - val_loss: 113.6422\n",
      "Epoch 237/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1386 - val_loss: 113.6325\n",
      "Epoch 238/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1323 - val_loss: 113.6230\n",
      "Epoch 239/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1262 - val_loss: 113.6138\n",
      "Epoch 240/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1203 - val_loss: 113.6048\n",
      "Epoch 241/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1145 - val_loss: 113.5958\n",
      "Epoch 242/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1088 - val_loss: 113.5869\n",
      "Epoch 243/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.1034 - val_loss: 113.5785\n",
      "Epoch 244/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0982 - val_loss: 113.5700\n",
      "Epoch 245/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0932 - val_loss: 113.5623\n",
      "Epoch 246/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0886 - val_loss: 113.5545\n",
      "Epoch 247/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0841 - val_loss: 113.5470\n",
      "Epoch 248/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0799 - val_loss: 113.5400\n",
      "Epoch 249/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0758 - val_loss: 113.5328\n",
      "Epoch 250/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0719 - val_loss: 113.5260\n",
      "Epoch 251/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0681 - val_loss: 113.5197\n",
      "Epoch 252/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0646 - val_loss: 113.5132\n",
      "Epoch 253/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0611 - val_loss: 113.5070\n",
      "Epoch 254/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0578 - val_loss: 113.5008\n",
      "Epoch 255/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0547 - val_loss: 113.4952\n",
      "Epoch 256/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0517 - val_loss: 113.4897\n",
      "Epoch 257/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0489 - val_loss: 113.4843\n",
      "Epoch 258/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0462 - val_loss: 113.4790\n",
      "Epoch 259/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0436 - val_loss: 113.4740\n",
      "Epoch 260/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0411 - val_loss: 113.4690\n",
      "Epoch 261/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0387 - val_loss: 113.4641\n",
      "Epoch 262/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0364 - val_loss: 113.4594\n",
      "Epoch 263/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0342 - val_loss: 113.4549\n",
      "Epoch 264/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0321 - val_loss: 113.4506\n",
      "Epoch 265/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0302 - val_loss: 113.4463\n",
      "Epoch 266/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0284 - val_loss: 113.4428\n",
      "Epoch 267/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0268 - val_loss: 113.4392\n",
      "Epoch 268/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0254 - val_loss: 113.4361\n",
      "Epoch 269/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0240 - val_loss: 113.4329\n",
      "Epoch 270/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0227 - val_loss: 113.4298\n",
      "Epoch 271/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0215 - val_loss: 113.4267\n",
      "Epoch 272/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0204 - val_loss: 113.4243\n",
      "Epoch 273/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0193 - val_loss: 113.4214\n",
      "Epoch 274/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0183 - val_loss: 113.4189\n",
      "Epoch 275/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0174 - val_loss: 113.4163\n",
      "Epoch 276/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0165 - val_loss: 113.4141\n",
      "Epoch 277/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0158 - val_loss: 113.4118\n",
      "Epoch 278/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0150 - val_loss: 113.4098\n",
      "Epoch 279/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0144 - val_loss: 113.4076\n",
      "Epoch 280/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0137 - val_loss: 113.4058\n",
      "Epoch 281/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0131 - val_loss: 113.4040\n",
      "Epoch 282/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0126 - val_loss: 113.4023\n",
      "Epoch 283/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0121 - val_loss: 113.4007\n",
      "Epoch 284/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0116 - val_loss: 113.3993\n",
      "Epoch 285/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0113 - val_loss: 113.3979\n",
      "Epoch 286/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0109 - val_loss: 113.3968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0105 - val_loss: 113.3955\n",
      "Epoch 288/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0102 - val_loss: 113.3943\n",
      "Epoch 289/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0099 - val_loss: 113.3932\n",
      "Epoch 290/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0096 - val_loss: 113.3920\n",
      "Epoch 291/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0094 - val_loss: 113.3910\n",
      "Epoch 292/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0091 - val_loss: 113.3901\n",
      "Epoch 293/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0089 - val_loss: 113.3890\n",
      "Epoch 294/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0087 - val_loss: 113.3880\n",
      "Epoch 295/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0084 - val_loss: 113.3870\n",
      "Epoch 296/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0082 - val_loss: 113.3861\n",
      "Epoch 297/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0081 - val_loss: 113.3851\n",
      "Epoch 298/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0079 - val_loss: 113.3844\n",
      "Epoch 299/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0077 - val_loss: 113.3835\n",
      "Epoch 300/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0076 - val_loss: 113.3827\n",
      "Epoch 301/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0074 - val_loss: 113.3819\n",
      "Epoch 302/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0073 - val_loss: 113.3811\n",
      "Epoch 303/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0072 - val_loss: 113.3806\n",
      "Epoch 304/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0070 - val_loss: 113.3797\n",
      "Epoch 305/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0069 - val_loss: 113.3791\n",
      "Epoch 306/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0068 - val_loss: 113.3784\n",
      "Epoch 307/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0067 - val_loss: 113.3779\n",
      "Epoch 308/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0066 - val_loss: 113.3773\n",
      "Epoch 309/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0065 - val_loss: 113.3767\n",
      "Epoch 310/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0064 - val_loss: 113.3762\n",
      "Epoch 311/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0063 - val_loss: 113.3756\n",
      "Epoch 312/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0063 - val_loss: 113.3750\n",
      "Epoch 313/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0062 - val_loss: 113.3746\n",
      "Epoch 314/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0061 - val_loss: 113.3740\n",
      "Epoch 315/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0061 - val_loss: 113.3737\n",
      "Epoch 316/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0060 - val_loss: 113.3731\n",
      "Epoch 317/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0060 - val_loss: 113.3727\n",
      "Epoch 318/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0059 - val_loss: 113.3723\n",
      "Epoch 319/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0059 - val_loss: 113.3719\n",
      "Epoch 320/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0058 - val_loss: 113.3715\n",
      "Epoch 321/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0058 - val_loss: 113.3710\n",
      "Epoch 322/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0057 - val_loss: 113.3706\n",
      "Epoch 323/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0057 - val_loss: 113.3702\n",
      "Epoch 324/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0056 - val_loss: 113.3699\n",
      "Epoch 325/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0056 - val_loss: 113.3696\n",
      "Epoch 326/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0056 - val_loss: 113.3692\n",
      "Epoch 327/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3689\n",
      "Epoch 328/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3685\n",
      "Epoch 329/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3684\n",
      "Epoch 330/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3683\n",
      "Epoch 331/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3681\n",
      "Epoch 332/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3678\n",
      "Epoch 333/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3678\n",
      "Epoch 334/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3676\n",
      "Epoch 335/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3676\n",
      "Epoch 336/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0055 - val_loss: 113.3675\n",
      "Epoch 337/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3673\n",
      "Epoch 338/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3672\n",
      "Epoch 339/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3670\n",
      "Epoch 340/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3669\n",
      "Epoch 341/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3669\n",
      "Epoch 342/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3668\n",
      "Epoch 343/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3666\n",
      "Epoch 344/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3664\n",
      "Epoch 345/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3665\n",
      "Epoch 346/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3664\n",
      "Epoch 347/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3664\n",
      "Epoch 348/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3662\n",
      "Epoch 349/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3661\n",
      "Epoch 350/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3660\n",
      "Epoch 351/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3659\n",
      "Epoch 352/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3660\n",
      "Epoch 353/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3659\n",
      "Epoch 354/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3658\n",
      "Epoch 355/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3656\n",
      "Epoch 356/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3657\n",
      "Epoch 357/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3656\n",
      "Epoch 358/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3655\n",
      "Epoch 360/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3655\n",
      "Epoch 361/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3655\n",
      "Epoch 362/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3654\n",
      "Epoch 363/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3653\n",
      "Epoch 364/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3654\n",
      "Epoch 365/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3653\n",
      "Epoch 366/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3652\n",
      "Epoch 367/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3652\n",
      "Epoch 368/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3652\n",
      "Epoch 369/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 370/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3652\n",
      "Epoch 371/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 372/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 373/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 374/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 375/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 376/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 377/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 378/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 379/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 380/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 381/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3651\n",
      "Epoch 382/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 383/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 384/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 385/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3650\n",
      "Epoch 386/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 387/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 388/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 389/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 390/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 391/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 392/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 393/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 394/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3649\n",
      "Epoch 395/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 396/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 397/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 398/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 399/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 400/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 401/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 402/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 403/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 404/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 405/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 406/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 407/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 408/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 409/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 410/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 411/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3648\n",
      "Epoch 412/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3647\n",
      "Epoch 413/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 414/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 415/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 416/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 417/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 418/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 419/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 420/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 421/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 422/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 423/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 424/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 425/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 426/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 427/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 428/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 429/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 430/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 432/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 433/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 434/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 435/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 436/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 437/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 438/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 439/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 440/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 441/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 442/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 443/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 444/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 445/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 446/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 447/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 448/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 449/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 450/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 451/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 452/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 453/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 454/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 455/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 456/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 457/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 458/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 459/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 460/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 461/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 462/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 463/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 464/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 465/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 466/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 467/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 468/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 469/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 470/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 471/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 472/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 473/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 474/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 475/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 476/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 477/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 478/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 479/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 480/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 481/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 482/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 483/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 484/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 485/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 486/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 487/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 488/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 489/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 490/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 491/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 492/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 493/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 494/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 495/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 496/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 497/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 498/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 499/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 500/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 501/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 502/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 504/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 505/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 506/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 507/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 508/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 509/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 510/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 511/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 512/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 513/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 514/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 515/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 516/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 517/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 518/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 519/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 520/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 521/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 522/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 523/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 524/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 525/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 526/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 527/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 528/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 529/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 530/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 531/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 532/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 533/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 534/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 535/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 536/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 537/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 538/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 539/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 540/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 541/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 542/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 543/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 544/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 545/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 546/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 547/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 548/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 549/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 550/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 551/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 552/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 553/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 554/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 555/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 556/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 557/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 558/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 559/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 560/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 561/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 562/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 563/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 564/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 565/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 566/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 567/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 568/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 569/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 570/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 571/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 572/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 573/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 574/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 576/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 577/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 578/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 579/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 580/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 581/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 582/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 583/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 584/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 585/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 586/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 587/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 588/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 589/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 590/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 591/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 592/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 593/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 594/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 595/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 596/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 597/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 598/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 599/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 600/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 601/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 602/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 603/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 604/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 605/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 606/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 607/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 608/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 609/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 610/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 611/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 612/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 613/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 614/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 615/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 616/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 617/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 618/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 619/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 620/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 621/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 622/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 623/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 624/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 625/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 626/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 627/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 628/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 629/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 630/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 631/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 632/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 633/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 634/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 635/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 636/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 637/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3642\n",
      "Epoch 638/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 639/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 640/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 641/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 642/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 643/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 644/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 645/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 646/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 648/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 649/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 650/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 651/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 652/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 653/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 654/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 655/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 656/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 657/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 658/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 659/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 660/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 661/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 662/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 663/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 664/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 665/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 666/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 667/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 668/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 669/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 670/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 671/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 672/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 673/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 674/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 675/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 676/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 677/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 678/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 679/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 680/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 681/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 682/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 683/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 684/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 685/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 686/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 687/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 688/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 689/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 690/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 691/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 692/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 693/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 694/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 695/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 696/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 697/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 698/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 699/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 700/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 701/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 702/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 703/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 704/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 705/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 706/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 707/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 708/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 709/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 710/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 711/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 712/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 713/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 714/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 715/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 716/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 717/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 718/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 720/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 721/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 722/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 723/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 724/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 725/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 726/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 727/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 728/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 729/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 730/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 731/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 732/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 733/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 734/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 735/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 736/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 737/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 738/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 739/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 740/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 741/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 742/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 743/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 744/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 745/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 746/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 747/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 748/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 749/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 750/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 751/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 752/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 753/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 754/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 755/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 756/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 757/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 758/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 759/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 760/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 761/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 762/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 763/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 764/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 765/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 766/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 767/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 768/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 769/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 770/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3642\n",
      "Epoch 771/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 772/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 773/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 774/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 775/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 776/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 777/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 778/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 779/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 780/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 781/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 782/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 783/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 784/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 785/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 786/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 787/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 788/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 789/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 790/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 792/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 793/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 794/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 795/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 796/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 797/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 798/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 799/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 800/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 801/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 802/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 803/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 804/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 805/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 806/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 807/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 808/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 809/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 810/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 811/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 812/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 813/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 814/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 815/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 816/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 817/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 818/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 819/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 820/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 821/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 822/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 823/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 824/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 825/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 826/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 827/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 828/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 829/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 830/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 831/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 832/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 833/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 834/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 835/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 836/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 837/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 838/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 839/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 840/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 841/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 842/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 843/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 844/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 845/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 846/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 847/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 848/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 849/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 850/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 851/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 852/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 853/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 854/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 855/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 856/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 857/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 858/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 859/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 860/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 861/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 862/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 864/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 865/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 866/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 867/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 868/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 869/1000\n",
      "90000/90000 [==============================] - 0s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 870/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 871/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 872/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 873/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 874/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 875/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 876/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 877/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 878/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 879/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 880/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 881/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 882/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 883/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 884/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 885/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 886/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 887/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 888/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 889/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 890/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 891/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 892/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 893/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 894/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 895/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 896/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 897/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 898/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 899/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 900/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 901/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 902/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 903/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 904/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 905/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 906/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 907/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 908/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 909/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 910/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 911/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 912/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 913/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 914/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 915/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 916/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 917/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 918/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 919/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 920/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 921/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 922/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 923/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 924/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 925/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 926/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 927/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 928/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 929/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 930/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 931/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 932/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 933/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 934/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3646\n",
      "Epoch 936/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 937/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 938/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 939/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 940/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 941/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 942/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 943/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 944/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 945/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 946/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 947/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 948/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 949/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 950/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 951/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 952/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 953/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 954/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 955/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 956/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 957/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 958/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 959/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 960/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 961/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 962/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 963/1000\n",
      "90000/90000 [==============================] - 1s 7us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 964/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 965/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 966/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 967/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 968/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 969/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 970/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 971/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 972/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 973/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 974/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 975/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 976/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 977/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 978/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 979/1000\n",
      "90000/90000 [==============================] - 1s 7us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 980/1000\n",
      "90000/90000 [==============================] - 1s 7us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 981/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 982/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 983/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 984/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 985/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 986/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 987/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 988/1000\n",
      "90000/90000 [==============================] - 0s 5us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 989/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 990/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 991/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 992/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 993/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 994/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 995/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3642\n",
      "Epoch 996/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 997/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3643\n",
      "Epoch 998/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n",
      "Epoch 999/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3644\n",
      "Epoch 1000/1000\n",
      "90000/90000 [==============================] - 1s 6us/sample - loss: 113.0054 - val_loss: 113.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ea4dc28208>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model = tf.keras.Sequential([\n",
    "    layers.Input((134)),\n",
    "    layers.Dense(128, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros'),\n",
    "    layers.Dense(64, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros'),\n",
    "    layers.Dense(32, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros'),\n",
    "    layers.Dense(16, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros'),\n",
    "    layers.Dense(4, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros'),\n",
    "    layers.Dense(1, activation=partial(tf.nn.leaky_relu, alpha=0.01), kernel_initializer='zeros')\n",
    "])\n",
    "lin_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.losses.mean_absolute_error) # try \"linear\" mse\n",
    "lin_model.fit(test_train,\n",
    "              electricity['meter_reading'],\n",
    "              batch_size=512,\n",
    "              validation_split=0.1,\n",
    "              epochs=1000\n",
    "             ) # 113.0054 on 785"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
